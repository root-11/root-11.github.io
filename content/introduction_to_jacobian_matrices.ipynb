{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Applied Computational Methods with NumPy, SciPy, and numdifftools\n",
    "\n",
    "This short introduction teaches fundamental techniques using Python's friends: NumPy, SciPy, and numdifftools. \n",
    "By the end of this tutorial, you will have an overview to start applying these tools to a wide range of real-world problems.\n",
    "\n",
    "**Overview**\n",
    "\n",
    "From basic matrix operations to sophisticated optimization techniques, culminating in real-world applications such as stock market simulations, this introduction gives a rapid overview to a wide array of topics. It is structured to provide a clear and progressive learning path, ensuring that each concept builds upon the previous one, ultimately leading to a deep understanding of applied computational methods.\n",
    "\n",
    "**Key Topics**\n",
    "\n",
    "1. **Fundamental Matrix Operations**:\n",
    "   - Addition, subtraction, dot product, cross product, inverse, and determinant calculations.\n",
    "   - Essential for understanding the mathematical foundation of more complex models.\n",
    "\n",
    "2. **Advanced Matrix Concepts**:\n",
    "   - Eigenvalues, eigenvectors, and their significance in various applications.\n",
    "   - Application of Jacobian matrices and the use of QR decomposition for stability analysis.\n",
    "\n",
    "3. **Nonlinear Systems and Stability**:\n",
    "   - Analysis of nonlinear systems using Jacobian matrices to determine stability and fixed points.\n",
    "   - Real-world applications in ecological models and mechanical systems.\n",
    "\n",
    "4. **Differential Equations and Optimization**:\n",
    "   - Solving systems of differential equations and applying optimization algorithms like Newton's method.\n",
    "   - Practical examples in engineering and machine learning.\n",
    "\n",
    "5. **Simulation and Predictive Modeling**:\n",
    "   - Using NumPy and numdifftools for simulating data and analyzing trends.\n",
    "   - Creating realistic models to predict future behavior and optimize systems.\n",
    "\n",
    "6. **Practical Optimization**:\n",
    "   - Developing and testing optimization strategies using historical and simulated data.\n",
    "   - Incorporating constraints and risk management into optimization decisions.\n",
    "\n",
    "7. **Real-World Applications and Case Studies**:\n",
    "   - Applying the learned techniques to real-world scenarios, such as stock market simulations.\n",
    "   - Detailed case studies that illustrate the practical benefits of computational methods.\n",
    "\n",
    "**Learning Outcomes**\n",
    "\n",
    "By the end of this introduction, you will:\n",
    "- Gain a solid foundation in matrix operations and their applications.\n",
    "- Understand how to analyze and solve nonlinear systems using advanced mathematical tools.\n",
    "- Develop skills to simulate and predict behaviors using Python.\n",
    "- Learn to optimize systems, balancing various constraints and objectives through computational techniques.\n",
    "- Have some practical knowledge and experience to apply these concepts in real-world problem-solving.\n",
    "\n",
    "**Audience**\n",
    "\n",
    "This introduction is designed for students, engineers, scientists, and anyone interested in leveraging computational methods for applied problem-solving. Whether you are new to computational techniques or looking to enhance your existing knowledge, this curriculum offers valuable insights and practical skills to help you succeed in a wide range of scientific and engineering fields.\n",
    "\n",
    "Whenever the reader encounters topics that are unfamiliar I recommend to explore the topic with ChatGTP4o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies\n",
    "# %% pip install numpy, scipy, numdifftools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Matrix operations\n",
    "\n",
    "Let's start with the basics.\n",
    "\n",
    "A matrix is an array or grid of values:\n",
    "\n",
    "\\begin{matrix}     1 & x & x^2 \\\\     1 & y & y^2 \\\\     1 & z & z^2 \\\\     \\end{matrix} \n",
    "\n",
    "A matrix has rows and columns.\n",
    "\n",
    "As this tutorial seeks to teach applied mathematics, I will use `numpy` as much as possible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create two matrices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([  # A matrix is an array (grid) of numbers. 2 rows, 3 columns.\n",
    "    [6, 4,24],\n",
    "    [1,-1, 8]\n",
    "])\n",
    "\n",
    "B = np.array([\n",
    "    [3,  0, 11],\n",
    "    [9, -7,  4]\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Matrix addition and subtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9,  4, 35],\n",
       "       [10, -8, 12]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A+B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To add two matrices: add the numbers in the matching positions.\n",
    "\n",
    "```\n",
    "6 + 3 =  9 |  4 +  0 =  4 | 24 + 11 = 35\n",
    "1 + 9 = 10 | -1 + -7 = -8 |  8 +  4 = 12\n",
    "```\n",
    "\n",
    "NB! The two matrices must have same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3,  4, 13],\n",
       "       [-8,  6,  4]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A-B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subtract: deduce the numbers in the matching position.\n",
    "\n",
    "```\n",
    "6 - 3 =  3 |  4 -  0 =  4 | 24 - 11 = 13\n",
    "1 - 9 = -8 | -1 - -7 = -6 |  8 -  4 =  4\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Multiplication - scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 60,  40, 240],\n",
       "       [ 10, -10,  80]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To multiply by a constant, multiple each value.\n",
    "\n",
    "NB! A constant is also called a **scalar**, so this *form* of multiplication is **scalar multiplication**.\n",
    "\n",
    "Another form of multiplication is the **dot product**:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Multiplication - dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 58,  64],\n",
       "       [139, 154]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.array([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "D = np.array([\n",
    "    [7,8],\n",
    "    [9,10],\n",
    "    [11,12]\n",
    "])\n",
    "np.dot(C,D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is produced by multiplying multiple values:\n",
    "\n",
    "$$ (1,2,3) \\cdot (7,9,11) = 1*7 + 2*9 + 3*11 = 58 $$\n",
    "$$ (1,2,3) \\cdot (8,10,12) = 1*8 + 2*10 + 3*12 = 64 $$\n",
    "$$ (4,5,6) \\cdot (7,9,11) = 4*7 + 5*9 + 6*11 = 139 $$\n",
    "$$ (4,5,6) \\cdot (8,10,12) = 4*8 + 5*10 + 6*12 = 154 $$\n",
    "\n",
    "Here is example of application, and the reason why it is very important the **order** by which matrices are multiplied.\n",
    "\n",
    "First we set up two matrices:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prices = np.array([\n",
    "    2,  # $ apple\n",
    "    0.75,  # $ cherry\n",
    "    0.2   # $ blueberry\n",
    "])\n",
    "\n",
    "sales = np.array([\n",
    "    [13, 9, 6, 14, 5],  # apple sales on monday, tuesday, wednesday, thursday, friday\n",
    "    [ 7, 5, 6,  4, 5],  # cherry sales M,T,W,T,F\n",
    "    [ 3, 2, 4,  0, 1]   # blueberry sales M,T,W,T,F\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I calculate the dot product of `prices` and `sales`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31.85 22.15 17.3  31.   13.95]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "revenue = np.dot(prices,sales)\n",
    "print(revenue)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue per day\n",
      " M: 31.85 $\n",
      "T: 22.15 $\n",
      "W: 17.3 $\n",
      "T: 31.0 $\n",
      "F: 13.95 $\n",
      "total revenue: 116.25\n"
     ]
    }
   ],
   "source": [
    "print(\"revenue per day\\n\", \"\\n\".join(f\"{i}: {j} $\" for i,j in zip(\"MTWTF\", list(revenue))))\n",
    "print(f\"total revenue: {sum(revenue)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I calculate the dot product of `sales` and `prices` which make no sense at all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1220.95  631.25  223.  ]\n"
     ]
    }
   ],
   "source": [
    "revenue_backwards = np.dot(sales, revenue)\n",
    "print(revenue_backwards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To multiply an MxN matrix, by a NxP matrix, \n",
    "\n",
    "the **N**s must be the same, \n",
    "\n",
    "**AND** the resulting matrix is an M*P matrix\n",
    "\n",
    "Examples:\n",
    "\n",
    "- Multiplying the MxN=1x3 with NxP=3x1 results in a 1x1 matrix\n",
    "- Multiplying the MxN=3x1 with NxP=1x3 results in a 3x3 matrix\n",
    "\n",
    "Numpy examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 2, 3]]),\n",
       " array([[4],\n",
       "        [5],\n",
       "        [6]]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.array([[1,2,3]])\n",
    "B = np.array([[4],[5],[6]])\n",
    "A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A,B)  # [1*4 + 2*5 + 3*6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  8, 12],\n",
       "       [ 5, 10, 15],\n",
       "       [ 6, 12, 18]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(B,A)  \n",
    "# [4*1 4*2 4*3]    [ 4  8 12]\n",
    "# [5*1 5*2 5*3]  = [ 5 10 15]\n",
    "# [6*1 6*2 6*3]    [ 6 12 18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The conclusion is that order of multiplication matters. The *commutative law of multiplication* is **void**.\n",
    "\n",
    "Here is another example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([[1,2],[3,4]])\n",
    "B = np.array([[2,0],[1,2]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4,  4],\n",
       "       [10,  8]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(A,B) #\n",
    "# [1*2+2*1 1*0+2*2] = [ 4, 4]\n",
    "# [3*2+4*1 3*0+4*2]   [10, 8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2,  4],\n",
       "       [ 7, 10]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(B,A) # \n",
    "# [2*1+0*3 2*2+0*4] = [2  4]\n",
    "# [1*1+2*3 1*2+2*4]   [7 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of basic operations\n",
    "\n",
    "1. Introduction to Matrices \n",
    "   1. Definition and types of matrices (row, column, square, diagonal, identity, zero matrix)\n",
    "   2.  Matrix notation and dimensions\n",
    "2. Matrix Addition and Subtraction\n",
    "   1. Element-wise operations\n",
    "   2. Properties (commutative, associative)\n",
    "3. Scalar Multiplication\n",
    "   1. Multiplying a matrix by a scalar\n",
    "   2. Properties (distributive, associative with respect to scalar multiplication)\n",
    "4. Matrix Multiplication (Dot Product)\n",
    "   1. Definition and calculation\n",
    "   2. Conditions for matrix multiplication\n",
    "   3. Properties (associative, distributive, non-commutative)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Advanced matrix operations\n",
    "\n",
    "In the next section we will now look at:\n",
    "\n",
    "1. Transpose of a Matrix\n",
    "   1. Definition and properties\n",
    "2. Determinants\n",
    "   1. Definition for 2x2 and 3x3 matrices\n",
    "   2. Expansion by minors and cofactors for larger matrices\n",
    "   3. Properties of determinants\n",
    "3. Inverse of a Matrix\n",
    "   1. Definition and properties\n",
    "   2. Conditions for existence (non-singular matrices)\n",
    "   3. Methods of finding the inverse (adjoint method, row reduction)\n",
    "\n",
    "As these methods are essential for solving Jacobian matrices using `numpy` and `scipy`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## a. Transpose \n",
    "\n",
    "**Definition and Properties**: The transpose of a matrix is obtained by swapping its rows with its columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Matrix:\n",
      " [[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "Transposed Matrix:\n",
      " [[1 4 7]\n",
      " [2 5 8]\n",
      " [3 6 9]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a matrix\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# Transpose the matrix\n",
    "A_transpose = np.transpose(A)\n",
    "\n",
    "print(\"Original Matrix:\\n\", A)\n",
    "print(\"Transposed Matrix:\\n\", A_transpose)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## b. Determinants\n",
    "\n",
    "The \"identity matrix\" is the matrix equivalent of the number \"1\"\n",
    "\n",
    "It is square, the diagonal is 1's and everything else is 0's.\n",
    "\n",
    "$$\n",
    "\n",
    "I  = \\begin{matrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{matrix}\n",
    "\n",
    "$$\n",
    "\n",
    "The determinant is a **special number** that can be calculated from a **square** `matrix`, that can be used to find the **inverse of a matrix**, which is useful in solving system of linear equations.\n",
    "\n",
    "\n",
    "If $ A = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix} $  then the determinant $|A| = ad-bc$\n",
    "\n",
    "If  $ A = \\begin{bmatrix} a & b & c \\\\ d & e & f \\\\ g & h & i \\end{bmatrix} $ then the determinant $ |A| = a(ei-fh) - b(di-fg) + c(dh-eg) $\n",
    "\n",
    "\n",
    "\n",
    "**Definition for 2x2 and 3x3 Matrices**:\n",
    "\n",
    "- For a $2 \\times 2$ matrix:\n",
    "  $$\n",
    "  \\text{det}(A) = ad - bc\n",
    "  $$\n",
    "\n",
    "- For a $3 \\times 3$ matrix:\n",
    "  $$\n",
    "  \\text{det}(A) = a(ei - fh) - b(di - fg) + c(dh - eg)\n",
    "  $$\n",
    "\n",
    "**Expansion by Minors and Cofactors for Larger Matrices**:\n",
    "\n",
    "Using NumPy for determinant calculation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant of 2x2 matrix: -2.0000000000000004\n",
      "Determinant of 3x3 matrix: 6.66133814775094e-16\n",
      "Determinant of 4x4 matrix: 0.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a 2x2 matrix\n",
    "A_2x2 = np.array([[1, 2],\n",
    "                  [3, 4]])\n",
    "\n",
    "# Create a 3x3 matrix\n",
    "A_3x3 = np.array([[1, 2, 3],\n",
    "                  [4, 5, 6],\n",
    "                  [7, 8, 9]])\n",
    "\n",
    "# Create a 4x4 matrix\n",
    "A_4x4 = np.array([[1, 2, 3, 4],\n",
    "                  [5, 6, 7, 8],\n",
    "                  [9, 10, 11, 12],\n",
    "                  [13, 14, 15, 16]])\n",
    "\n",
    "# Calculate determinants\n",
    "det_2x2 = np.linalg.det(A_2x2)\n",
    "det_3x3 = np.linalg.det(A_3x3)\n",
    "det_4x4 = np.linalg.det(A_4x4)\n",
    "\n",
    "print(\"Determinant of 2x2 matrix:\", det_2x2)\n",
    "print(\"Determinant of 3x3 matrix:\", det_3x3)\n",
    "print(\"Determinant of 4x4 matrix:\", det_4x4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## c. Inverse of a Matrix\n",
    "\n",
    "Matrices don't divide. They multiple the inverse: $$A/B = A(1/B) = AB^{-1}$$\n",
    "\n",
    "\n",
    "**Definition and Properties**: The inverse of a matrix \\(A\\) is another matrix \\(A^{-1}\\) such that \\(AA^{-1} = A^{-1}A = I\\), where \\(I\\) is the identity matrix. A matrix must be non-singular (i.e., its determinant is non-zero) to have an inverse.\n",
    "\n",
    "**Conditions for Existence**: The matrix must be square and have a non-zero determinant.\n",
    "\n",
    "**Methods of Finding the Inverse**:\n",
    "\n",
    "Using NumPy for matrix inversion:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of the matrix:\n",
      " [[-2.   1. ]\n",
      " [ 1.5 -0.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create a non-singular matrix\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4]])\n",
    "\n",
    "# Check if the matrix is invertible by ensuring its determinant is non-zero\n",
    "det_A = np.linalg.det(A)\n",
    "if det_A != 0:\n",
    "    # Calculate the inverse\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    print(\"Inverse of the matrix:\\n\", A_inv)\n",
    "else:\n",
    "    print(\"The matrix is singular and does not have an inverse.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Here's an example of using SciPy for the same operations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of the matrix using SciPy:\n",
      " [[-1.08333333  0.58333333]\n",
      " [ 0.91666667 -0.41666667]]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import det, inv\n",
    "\n",
    "# Create a non-singular matrix\n",
    "B = np.array([[5, 7],\n",
    "              [11, 13]])\n",
    "\n",
    "# Check if the matrix is invertible by ensuring its determinant is non-zero\n",
    "det_B = det(B)\n",
    "if det_B != 0:\n",
    "    # Calculate the inverse\n",
    "    B_inv = inv(B)\n",
    "    print(\"Inverse of the matrix using SciPy:\\n\", B_inv)\n",
    "else:\n",
    "    print(\"The matrix is singular and does not have an inverse.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Solving equations with the inverse\n",
    "\n",
    "The inverse is useful for solving a system of equations:\n",
    "\n",
    "\n",
    "$$\\begin{gather} \n",
    "\\begin{bmatrix} x_{1} & x_{2} \\end{bmatrix} \\cdot \\begin{bmatrix} 3 & 3.5 \\\\ 3.2 & 3.6 \\end{bmatrix} = \\begin{bmatrix} 118.4 & 135.2 \\end{bmatrix}\n",
    "\\end{gather}$$\n",
    "\n",
    "which may be viewed as: $ XA=B $\n",
    "\n",
    "To solve it the inverse of A can be used as $ X = BA^{-1} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A : [[3.  3.5]\n",
      " [3.2 3.6]]\n",
      "B : [[118.4 135.2]]\n",
      "inv_A : [[-9.    8.75]\n",
      " [ 8.   -7.5 ]]\n",
      "solution : [[16. 22.]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[3,   3.5],\n",
    "              [3.2, 3.6]])\n",
    "A_inv = np.linalg.inv(A)\n",
    "B = np.array([[118.4, 135.2]])\n",
    "solution = np.dot(B,A_inv)\n",
    "for name, item in zip([\"A\", \"B\", \"inv_A\", \"solution\"],[A,B,A_inv, solution]): print(name, \":\", item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "These examples demonstrate the use of NumPy and SciPy for advanced matrix operations, including transposing matrices, calculating determinants, and finding matrix inverses. These operations are foundational for more advanced topics in linear algebra and multivariable calculus, such as Jacobian matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! The $AA^{-1} == A^{-1}A = I $, but sometimes there is no inverse at all. For those cases numpy will typically show you a division by zero error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Specialized Matrix Operations\n",
    "\n",
    "The next section is a dive into 3 specialized operations\n",
    "\n",
    "1. Cross Product\n",
    "   1. Definition and calculation for vectors in $\\R^{3}$\n",
    "   2. Geometric interpretation\n",
    "2. Eigenvalues and Eigenvectors\n",
    "   1. Definition and significance\n",
    "   2. Characteristic equation\n",
    "   3. Methods of finding eigenvalues and eigenvectors\n",
    "3. Matrix Decompositions\n",
    "   1. LU decomposition\n",
    "   2. QR decomposition\n",
    "   3. Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## a. Cross Product\n",
    "\n",
    "**Definition and Calculation for Vectors in $\\R^{3}$**:\n",
    "The cross product of two vectors ${u}$ and ${v}$ in $\\R^{3}$ is another vector that is perpendicular to both ${u}$ and ${v}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Product of u and v: [-3  6 -3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define two vectors\n",
    "u = np.array([1, 2, 3])\n",
    "v = np.array([4, 5, 6])\n",
    "\n",
    "# Calculate the cross product\n",
    "cross_product = np.cross(u, v)\n",
    "\n",
    "print(\"Cross Product of u and v:\", cross_product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## b. Eigenvalues and Eigenvectors\n",
    "\n",
    "**Definition and Significance**: Eigenvalues and eigenvectors are important in many areas of linear algebra, including stability analysis, quantum mechanics, and vibrations analysis.\n",
    "\n",
    "**Characteristic Equation**: For a square matrix $A$, the eigenvalues $\\lambda$ are found from the equation $\\det(A - \\lambda I) = 0$.\n",
    "\n",
    "**Methods of Finding Eigenvalues and Eigenvectors**:\n",
    "\n",
    "Using NumPy to find eigenvalues and eigenvectors:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues: [3. 2.]\n",
      "Eigenvectors:\n",
      " [[0.89442719 0.70710678]\n",
      " [0.4472136  0.70710678]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define a square matrix\n",
    "A = np.array([[4, -2],\n",
    "              [1, 1]])\n",
    "\n",
    "# Calculate eigenvalues and eigenvectors\n",
    "eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "\n",
    "print(\"Eigenvalues:\", eigenvalues)\n",
    "print(\"Eigenvectors:\\n\", eigenvectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained example: Vibration Analysis of a Mechanical System\n",
    "\n",
    "**Context**:\n",
    "Consider a mechanical system such as a building, a bridge, or a car suspension system. Engineers need to ensure that the system can withstand various forces and vibrations. One critical aspect of this analysis involves understanding the natural frequencies and modes of vibration of the structure. This is where eigenvalues and eigenvectors come into play.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "In mechanical systems, vibrations can be modeled using matrices. For instance, the stiffness matrix $ K $ and the mass matrix $ M $ describe the properties of the system. The natural frequencies and modes of vibration are found by solving the eigenvalue problem.\n",
    "\n",
    "For simplicity, let's consider a 2-degree-of-freedom system such as a two-mass-spring system. The equations of motion for such a system can be written in matrix form as:\n",
    "\n",
    "$$\n",
    "M \\frac{d^2 \\mathbf{u}}{dt^2} + K \\mathbf{u} = 0\n",
    "$$\n",
    "\n",
    "where $ \\mathbf{u} $ is the displacement vector.\n",
    "\n",
    "**System Description:**\n",
    "\n",
    "- **Masses**: $ m_1 = 1 $ kg and $ m_2 = 1 $ kg.\n",
    "- **Springs**: Spring constants $ k_1 = 2 $ N/m and $ k_2 = 2 $ N/m.\n",
    "\n",
    "The mass matrix $ M $ and the stiffness matrix $ K $ are:\n",
    "\n",
    "$$\n",
    "M = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "K = \\begin{bmatrix} 4 & -2 \\\\ -2 & 2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Eigenvalue Problem:**\n",
    "\n",
    "To find the natural frequencies and modes, we solve the generalized eigenvalue problem:\n",
    "\n",
    "$$\n",
    "(K - \\lambda M) \\mathbf{v} = 0\n",
    "$$\n",
    "\n",
    "This simplifies to solving:\n",
    "\n",
    "$$\n",
    "(K - \\lambda I) \\mathbf{v} = 0\n",
    "$$\n",
    "\n",
    "where $ I $ is the identity matrix.\n",
    "\n",
    "**Using NumPy to Solve for Eigenvalues and Eigenvectors:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues (natural frequencies): [5.23606798 0.76393202]\n",
      "Eigenvectors (modes of vibration):\n",
      " [[ 0.85065081  0.52573111]\n",
      " [-0.52573111  0.85065081]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define the mass matrix M\n",
    "M = np.array([[1, 0],\n",
    "              [0, 1]])\n",
    "\n",
    "# Define the stiffness matrix K\n",
    "K = np.array([[4, -2],\n",
    "              [-2, 2]])\n",
    "\n",
    "# Solve the eigenvalue problem\n",
    "eigenvalues, eigenvectors = np.linalg.eig(K)\n",
    "\n",
    "print(\"Eigenvalues (natural frequencies):\", eigenvalues)\n",
    "print(\"Eigenvectors (modes of vibration):\\n\", eigenvectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation of Results:**\n",
    "\n",
    "- **Eigenvalues**: The eigenvalues correspond to the square of the natural frequencies of the system. For instance, if the eigenvalues are $\\lambda_1 = 5.236$ and $\\lambda_2 = 0.764$, the natural frequencies are $\\sqrt{5.236} \\approx 2.29$ Hz and $\\sqrt{0.764} \\approx 0.87$ Hz.\n",
    "- **Eigenvectors**: The eigenvectors correspond to the mode shapes of the vibrations. Each eigenvector indicates how the masses move relative to each other at a particular natural frequency.\n",
    "\n",
    "**Practical Significance:**\n",
    "\n",
    "Understanding the natural frequencies and mode shapes of a mechanical system is crucial for several reasons:\n",
    "\n",
    "1. **Avoiding Resonance**: Resonance occurs when an external force matches a system's natural frequency, leading to large amplitude vibrations that can cause structural failure. Engineers design systems to avoid operating at these frequencies.\n",
    "   \n",
    "2. **Structural Health Monitoring**: By measuring the natural frequencies of a structure and comparing them to the expected values, engineers can detect damage or changes in the structure's integrity.\n",
    "\n",
    "3. **Design Optimization**: Knowing the mode shapes helps in designing structures that can withstand dynamic loads and vibrations more effectively, ensuring safety and longevity.\n",
    "\n",
    "**Real-World Example:**\n",
    "\n",
    "Imagine designing a skyscraper. During an earthquake, the building will experience vibrations. If the building's natural frequency matches the frequency of the seismic waves, it can lead to catastrophic failure. By calculating the eigenvalues and eigenvectors, engineers can adjust the design (e.g., adding dampers or changing materials) to shift the natural frequencies away from the expected range of seismic activity, ensuring the building remains stable and safe during an earthquake.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "Eigenvalues and eigenvectors play a fundamental role in understanding and designing systems subjected to dynamic forces. This analysis helps engineers ensure the safety, reliability, and longevity of structures by predicting their response to various loads and avoiding resonance conditions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## c. Matrix Decompositions\n",
    "\n",
    "**LU Decomposition**:\n",
    "LU decomposition decomposes a matrix into a lower triangular matrix $L$ and an upper triangular matrix $U$.\n",
    "\n",
    "Using SciPy for LU decomposition:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L matrix:\n",
      " [[1.         0.        ]\n",
      " [0.66666667 1.        ]]\n",
      "U matrix:\n",
      " [[6. 3.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "# Define a square matrix\n",
    "A = np.array([[4, 3],\n",
    "              [6, 3]])\n",
    "\n",
    "# Perform LU decomposition\n",
    "P, L, U = lu(A)\n",
    "\n",
    "print(\"L matrix:\\n\", L)\n",
    "print(\"U matrix:\\n\", U)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**QR Decomposition**:\n",
    "QR decomposition decomposes a matrix into an orthogonal matrix \\(Q\\) and an upper triangular matrix \\(R\\).\n",
    "\n",
    "Using NumPy for QR decomposition:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q matrix:\n",
      " [[-0.12309149  0.90453403  0.40824829]\n",
      " [-0.49236596  0.30151134 -0.81649658]\n",
      " [-0.86164044 -0.30151134  0.40824829]]\n",
      "R matrix:\n",
      " [[ -8.1240384   -9.6011363  -11.07823419]\n",
      " [  0.           0.90453403   1.80906807]\n",
      " [  0.           0.           0.        ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define a matrix\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# Perform QR decomposition\n",
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "print(\"Q matrix:\\n\", Q)\n",
    "print(\"R matrix:\\n\", R)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Singular Value Decomposition (SVD)**:\n",
    "SVD decomposes a matrix into three other matrices $U$, $\\Sigma$, and $V^*$.\n",
    "\n",
    "Using NumPy for SVD:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U matrix:\n",
      " [[-0.21483724  0.88723069  0.40824829]\n",
      " [-0.52058739  0.24964395 -0.81649658]\n",
      " [-0.82633754 -0.38794278  0.40824829]]\n",
      "Singular values:\n",
      " [1.68481034e+01 1.06836951e+00 1.47280825e-16]\n",
      "V^* matrix:\n",
      " [[-0.47967118 -0.57236779 -0.66506441]\n",
      " [-0.77669099 -0.07568647  0.62531805]\n",
      " [ 0.40824829 -0.81649658  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define a matrix\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# Perform Singular Value Decomposition\n",
    "U, S, Vt = np.linalg.svd(A)\n",
    "\n",
    "print(\"U matrix:\\n\", U)\n",
    "print(\"Singular values:\\n\", S)\n",
    "print(\"V^* matrix:\\n\", Vt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Summary\n",
    "\n",
    "These examples demonstrate the use of NumPy and SciPy for specialized matrix operations, including the cross product, eigenvalues and eigenvectors, LU decomposition, QR decomposition, and singular value decomposition (SVD). These operations are foundational for various advanced applications in linear algebra and related fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Systems of Linear Equations\n",
    "\n",
    "Now the interesting parts begin. Below are examples of representing and solving systems of linear equations using NumPy and SciPy.\n",
    "\n",
    "## a. Representing Systems with Matrices\n",
    "\n",
    "A system of linear equations can be represented in matrix form $AX = B$, where $A$ is the matrix of coefficients, $X$ is the column vector of variables, and $B$ is the column vector of constants.\n",
    "\n",
    "Consider, for example, the following system of equations:\n",
    "$$ \n",
    "2x + 3y = -5 \\\\\n",
    "-4x + 6y = 9 \n",
    "$$\n",
    "\n",
    "This can be represented as:\n",
    "$$ \n",
    "\\begin{pmatrix}  2 & 3 \\\\ -4 & 6  \\end{pmatrix} \n",
    "\\begin{pmatrix} x \\\\ y \\end{pmatrix} \n",
    "= \n",
    "\\begin{pmatrix} -5 \\\\ 9 \\end{pmatrix} \n",
    "$$\n",
    "\n",
    "Using NumPy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix A:\n",
      " [[ 2  3]\n",
      " [-4  6]]\n",
      "Vector B:\n",
      " [-5  9]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Coefficient matrix A\n",
    "A = np.array([[2, 3],\n",
    "              [-4, 6]])\n",
    "\n",
    "# Constant vector B\n",
    "B = np.array([-5, 9])\n",
    "\n",
    "print(\"Matrix A:\\n\", A)\n",
    "print(\"Vector B:\\n\", B)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## b. Solving Systems Using Gaussian Elimination\n",
    "\n",
    "Gaussian elimination involves transforming the matrix into row echelon form and then performing back substitution.\n",
    "\n",
    "Using SciPy's `linalg.solve` which internally performs Gaussian elimination:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution Vector X:\n",
      " [-2.375      -0.08333333]\n"
     ]
    }
   ],
   "source": [
    "from scipy.linalg import solve\n",
    "\n",
    "# Solve the system of equations\n",
    "X = solve(A, B)\n",
    "\n",
    "print(\"Solution Vector X:\\n\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `solve` raises an exception, it is most likely because the set of equations have no solution. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Using Inverse Matrices to Solve Systems\n",
    "\n",
    "If $A$ is invertible, the solution to $AX = B$ can be found as $X = A^{-1}B$.\n",
    "\n",
    "Using NumPy to find the inverse and solve the system:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inverse of Matrix A:\n",
      " [[ 0.25       -0.125     ]\n",
      " [ 0.16666667  0.08333333]]\n",
      "Solution Vector X using inverse:\n",
      " [-2.375      -0.08333333]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Check if the matrix is invertible by computing the determinant\n",
    "if np.linalg.det(A) != 0:\n",
    "    # Calculate the inverse of A\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    \n",
    "    # Solve for X using the inverse\n",
    "    X = np.dot(A_inv, B)\n",
    "    \n",
    "    print(\"Inverse of Matrix A:\\n\", A_inv)\n",
    "    print(\"Solution Vector X using inverse:\\n\", X)\n",
    "else:\n",
    "    print(\"Matrix A is singular and cannot be inverted.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example with a different System\n",
    "\n",
    "Consider the system:\n",
    "$$ \n",
    "x + 2y + 3z = 4 \\\\\n",
    "4x + 5y + 6z = 7 \\\\\n",
    "7x + 8y + 9z = 10 \n",
    "$$\n",
    "\n",
    "This can be represented as:\n",
    "$$ \n",
    "\\begin{pmatrix}  1 & 2 & 3 \\\\  4 & 5 & 6 \\\\  7 & 8 & 9  \\end{pmatrix} \n",
    "\\begin{pmatrix} x \\\\  y \\\\ z  \\end{pmatrix} \n",
    "= \n",
    "\\begin{pmatrix} 4 \\\\ 7 \\\\ 10 \\end{pmatrix} \n",
    "$$\n",
    "\n",
    "Using NumPy and SciPy to solve this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution Vector X using solve:\n",
      " [-2.  3.  0.]\n",
      "Solution Vector X using inverse:\n",
      " [8. 0. 0.]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_221320/1292542544.py:14: LinAlgWarning: Ill-conditioned matrix (rcond=1.54198e-18): result may not be accurate.\n",
      "  X = solve(A, B)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import solve\n",
    "\n",
    "# Coefficient matrix A\n",
    "A = np.array([[1, 2, 3],\n",
    "              [4, 5, 6],\n",
    "              [7, 8, 9]])\n",
    "\n",
    "# Constant vector B\n",
    "B = np.array([4, 7, 10])\n",
    "\n",
    "# Solve the system using Gaussian elimination\n",
    "try:\n",
    "    X = solve(A, B)\n",
    "    print(\"Solution Vector X using solve:\\n\", X)\n",
    "except np.linalg.LinAlgError:\n",
    "    print(\"Matrix A is singular and the system does not have a unique solution.\")\n",
    "\n",
    "# Solve the system using the inverse if the matrix is invertible\n",
    "if np.linalg.det(A) != 0:\n",
    "    A_inv = np.linalg.inv(A)\n",
    "    X = np.dot(A_inv, B)\n",
    "    print(\"Solution Vector X using inverse:\\n\", X)\n",
    "else:\n",
    "    print(\"Matrix A is singular and cannot be inverted.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "These examples illustrate how to represent systems of linear equations with matrices, solve them using Gaussian elimination, and solve them using inverse matrices in NumPy and SciPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Vector Calculus Basics\n",
    "\n",
    "This section is about the basics of vector calculus.\n",
    "\n",
    "## a. Vector Functions\n",
    "\n",
    "**Definition and Examples**:\n",
    "A vector function is a function that takes one or more variables and returns a vector. \n",
    "\n",
    "For example, consider the vector function $F(x, y) = [f_{1}(x, y), f_{2}(x, y)] = [x^{2} + y^{2}, 2xy]$.\n",
    "\n",
    "**Operations on Vector Functions**:\n",
    "\n",
    "1. **Addition**:\n",
    "2. **Scalar Multiplication**:\n",
    "3. **Dot Product**:\n",
    "\n",
    "Using NumPy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F(x, y): [5 4]\n",
      "G(x, y): [ 0.84147098 -0.41614684]\n",
      "F + G: [5.84147098 3.58385316]\n",
      "Scalar * F: [15 12]\n",
      "Dot Product of F and G: 2.5427675778509133\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Define vector functions\n",
    "def F(x, y):\n",
    "    return np.array([x**2 + y**2, 2*x*y])\n",
    "\n",
    "def G(x, y):\n",
    "    return np.array([np.sin(x), np.cos(y)])\n",
    "\n",
    "# Vector addition\n",
    "def add_vectors(F, G, x, y):\n",
    "    return F(x, y) + G(x, y)\n",
    "\n",
    "# Scalar multiplication\n",
    "def scalar_multiply(F, scalar, x, y):\n",
    "    return scalar * F(x, y)\n",
    "\n",
    "# Dot product (for 2D vectors)\n",
    "def dot_product(F, G, x, y):\n",
    "    return np.dot(F(x, y), G(x, y))\n",
    "\n",
    "# Example values\n",
    "x, y = 1, 2\n",
    "scalar = 3\n",
    "\n",
    "print(\"F(x, y):\", F(x, y))\n",
    "print(\"G(x, y):\", G(x, y))\n",
    "print(\"F + G:\", add_vectors(F, G, x, y))\n",
    "print(\"Scalar * F:\", scalar_multiply(F, scalar, x, y))\n",
    "print(\"Dot Product of F and G:\", dot_product(F, G, x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Partial Derivatives\n",
    "\n",
    "**Definition and Interpretation**:\n",
    "Partial derivatives represent the rate of change of a function with respect to one variable while keeping other variables constant.\n",
    "\n",
    "Using NumPy and SciPy for calculating partial derivatives:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Partial derivative with respect to x: 4.000000000888178\n",
      "Partial derivative with respect to y: 13.000000001998401\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a multivariable function\n",
    "def f(x, y):\n",
    "    return x**2 * y + y**3\n",
    "\n",
    "# Create derivative functions\n",
    "partial_x = nd.Derivative(lambda x: f(x, y), step=1e-6)\n",
    "partial_y = nd.Derivative(lambda y: f(x, y), step=1e-6)\n",
    "\n",
    "# Example values\n",
    "x, y = 1, 2\n",
    "\n",
    "print(\"Partial derivative with respect to x:\", partial_x(x))\n",
    "print(\"Partial derivative with respect to y:\", partial_y(y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Gradient, Divergence, and Curl\n",
    "\n",
    "**Gradient**:\n",
    "The gradient of a scalar function is a vector that points in the direction of the greatest rate of increase of the function.\n",
    "\n",
    "Using NumPy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f at (x, y): [ 2. 12.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a scalar function\n",
    "def f(x, y):\n",
    "    return x**2 + y**3\n",
    "\n",
    "# Gradient calculation using numdifftools\n",
    "def gradient(f, x, y):\n",
    "    df_dx = nd.Derivative(lambda x: f(x, y))(x)\n",
    "    df_dy = nd.Derivative(lambda y: f(x, y))(y)\n",
    "    return np.array([df_dx, df_dy])\n",
    "\n",
    "# Example values\n",
    "x, y = 1, 2\n",
    "\n",
    "print(\"Gradient of f at (x, y):\", gradient(f, x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Divergence**:\n",
    "The divergence of a vector field is a scalar function that represents the rate of change of the field's magnitude.\n",
    "\n",
    "Using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divergence of F at (x, y): 6.000000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a vector function\n",
    "def F(x, y):\n",
    "    return np.array([x**2, y**2])\n",
    "\n",
    "# Divergence calculation using numdifftools\n",
    "def divergence(F, x, y):\n",
    "    div_x = nd.Derivative(lambda x: F(x, y)[0])(x)\n",
    "    div_y = nd.Derivative(lambda y: F(x, y)[1])(y)\n",
    "    return div_x + div_y\n",
    "\n",
    "# Example values\n",
    "x, y = 1, 2\n",
    "\n",
    "print(\"Divergence of F at (x, y):\", divergence(F, x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Curl**:\n",
    "The curl of a vector field in 3D represents the rotation of the field.\n",
    "\n",
    "Using NumPy and numdifftools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Curl of F at (x, y, z): [-1.12132525e-14 -2.22044605e-15 -2.66453526e-15]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a vector function in 3D\n",
    "def F(x, y, z):\n",
    "    return np.array([y*z, x*z, x*y])\n",
    "\n",
    "# Curl calculation using numdifftools\n",
    "def curl(F, x, y, z):\n",
    "    df2_dy = nd.Derivative(lambda y: F(x, y, z)[2])(y)\n",
    "    df1_dz = nd.Derivative(lambda z: F(x, y, z)[1])(z)\n",
    "    curl_x = df2_dy - df1_dz\n",
    "\n",
    "    df0_dz = nd.Derivative(lambda z: F(x, y, z)[0])(z)\n",
    "    df2_dx = nd.Derivative(lambda x: F(x, y, z)[2])(x)\n",
    "    curl_y = df0_dz - df2_dx\n",
    "\n",
    "    df1_dx = nd.Derivative(lambda x: F(x, y, z)[1])(x)\n",
    "    df0_dy = nd.Derivative(lambda y: F(x, y, z)[0])(y)\n",
    "    curl_z = df1_dx - df0_dy\n",
    "\n",
    "    return np.array([curl_x, curl_y, curl_z])\n",
    "\n",
    "# Example values\n",
    "x, y, z = 1, 2, 3\n",
    "\n",
    "print(\"Curl of F at (x, y, z):\", curl(F, x, y, z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "These examples demonstrate how to perform basic vector calculus operations, including operations on vector functions, partial derivatives, and calculating the gradient, divergence, and curl using NumPy and SciPy. These operations are foundational in many applications in physics and engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Introduction to Multivariable Calculus\n",
    "\n",
    "This section introduces multivariable calculus.\n",
    "\n",
    "## a. Multivariable Functions\n",
    "\n",
    "**Definition and Examples**:\n",
    "A multivariable function is a function with more than one input variable. For example, $f(x, y) = x^2 + y^2$ is a function of two variables.\n",
    "\n",
    "**Domain and Range**:\n",
    "The domain of a multivariable function is the set of all possible input values, while the range is the set of all possible output values.\n",
    "\n",
    "Example function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function values for f(x, y): [17 29 45]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a multivariable function\n",
    "def f(x, y):\n",
    "    return x**2 + y**2\n",
    "\n",
    "# Example values\n",
    "x = np.array([1, 2, 3])\n",
    "y = np.array([4, 5, 6])\n",
    "\n",
    "# Calculate function values\n",
    "result = f(x, y)\n",
    "\n",
    "print(\"Function values for f(x, y):\", result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Limits and Continuity\n",
    "\n",
    "**Definition and Properties**:\n",
    "The limit of a multivariable function as $(x, y) \\to (a, b)$ is the value that $f(x, y)$ approaches as $(x, y)$ gets arbitrarily close to $(a, b)$.\n",
    "\n",
    "**Techniques for Evaluating Limits**:\n",
    "Using substitution and path approach.\n",
    "\n",
    "Example using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function values near (1, 1):\n",
      " [[ 0.          0.00224215  0.00447926 ...  0.19448168  0.19625301\n",
      "   0.1980198 ]\n",
      " [-0.00224215  0.          0.00223713 ...  0.19232339  0.19409626\n",
      "   0.19586461]\n",
      " [-0.00447926 -0.00223713  0.         ...  0.19016808  0.19194248\n",
      "   0.19371236]\n",
      " ...\n",
      " [-0.19448168 -0.19232339 -0.19016808 ...  0.          0.00184162\n",
      "   0.00367984]\n",
      " [-0.19625301 -0.19409626 -0.19194248 ... -0.00184162  0.\n",
      "   0.00183823]\n",
      " [-0.1980198  -0.19586461 -0.19371236 ... -0.00367984 -0.00183823\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define a multivariable function\n",
    "def f(x, y):\n",
    "    return (x**2 - y**2) / (x**2 + y**2)\n",
    "\n",
    "# Evaluate limit as (x, y) approaches (1, 1)\n",
    "x = np.linspace(0.9, 1.1, 100)\n",
    "y = np.linspace(0.9, 1.1, 100)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = f(X, Y)\n",
    "\n",
    "print(\"Function values near (1, 1):\\n\", Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Differentiation of Multivariable Functions\n",
    "\n",
    "**Partial Derivatives**:\n",
    "Partial derivatives represent the rate of change of a function with respect to one variable while keeping other variables constant.\n",
    "\n",
    "Using NumPy and SciPy for partial derivatives:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f at (x, y): [ 4. 13.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a multivariable function\n",
    "def f(x, y):\n",
    "    return x**2 * y + y**3\n",
    "\n",
    "# Gradient calculation using numdifftools\n",
    "def gradient(f, x, y):\n",
    "    df_dx = nd.Derivative(lambda x: f(x, y))(x)\n",
    "    df_dy = nd.Derivative(lambda y: f(x, y))(y)\n",
    "    return np.array([df_dx, df_dy])\n",
    "\n",
    "# Example values\n",
    "x, y = 1, 2\n",
    "\n",
    "print(\"Gradient of f at (x, y):\", gradient(f, x, y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Differentiability and Linearization**:\n",
    "A function is differentiable if it can be well approximated by a linear function near a point.\n",
    "\n",
    "Example using NumPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear approximation near (1, 2): 11.700000000000001\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a multivariable function\n",
    "def f(x, y):\n",
    "    return x**2 * y + y**3\n",
    "\n",
    "# Gradient calculation (partial derivatives)\n",
    "def gradient(f, x, y):\n",
    "    df_dx = nd.Derivative(lambda x: f(x, y))(x)\n",
    "    df_dy = nd.Derivative(lambda y: f(x, y))(y)\n",
    "    return np.array([df_dx, df_dy])\n",
    "\n",
    "# Linear approximation of f near (x0, y0)\n",
    "def linear_approximation(f, x0, y0, x, y):\n",
    "    f0 = f(x0, y0)\n",
    "    grad = gradient(f, x0, y0)\n",
    "    return f0 + grad[0] * (x - x0) + grad[1] * (y - y0)\n",
    "\n",
    "# Example values\n",
    "x0, y0 = 1, 2\n",
    "x, y = 1.1, 2.1\n",
    "\n",
    "print(\"Linear approximation near (1, 2):\", linear_approximation(f, x0, y0, x, y))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "These examples demonstrate how to perform basic operations in multivariable calculus using NumPy and SciPy. This includes defining multivariable functions, evaluating limits and continuity, and differentiating multivariable functions. These operations are foundational for more advanced topics in calculus and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Jacobian Matrices\n",
    "\n",
    "Finally we have reached the required knowledge to look at Jacobian matrices.\n",
    "\n",
    "## a. Definition and Intuition\n",
    "\n",
    "The Jacobian matrix of a vector-valued function $ \\mathbf{F} : \\mathbb{R}^n \\to \\mathbb{R}^m $ is a matrix of all first-order partial derivatives. If $ \\mathbf{F} = [F_1, F_2, \\ldots, F_m] $ and $ \\mathbf{x} = [x_1, x_2, \\ldots, x_n] $, then the Jacobian matrix $ J $ is defined as:\n",
    "\n",
    "$$\n",
    "J = \\begin{bmatrix}\n",
    "\\frac{\\partial F_1}{\\partial x_1} & \\frac{\\partial F_1}{\\partial x_2} & \\cdots & \\frac{\\partial F_1}{\\partial x_n} \\\\\n",
    "\\frac{\\partial F_2}{\\partial x_1} & \\frac{\\partial F_2}{\\partial x_2} & \\cdots & \\frac{\\partial F_2}{\\partial x_n} \\\\\n",
    "\\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial F_m}{\\partial x_1} & \\frac{\\partial F_m}{\\partial x_2} & \\cdots & \\frac{\\partial F_m}{\\partial x_n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "## b. Calculation of Jacobian Matrices\n",
    "\n",
    "**Example**: Let $ \\mathbf{F}(x, y) = \\begin{bmatrix} x^2 y + y^3 \\\\ 2x + y^2 \\end{bmatrix} $.\n",
    "\n",
    "Using NumPy and `numdifftools` to compute the Jacobian matrix:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian matrix at point [1. 2.] :\n",
      " [[ 4. 13.]\n",
      " [ 2.  4.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a vector-valued function\n",
    "def F(vars):\n",
    "    x, y = vars\n",
    "    return np.array([x**2 * y + y**3, 2*x + y**2])\n",
    "\n",
    "# Create a Jacobian function using numdifftools\n",
    "jacobian = nd.Jacobian(F)\n",
    "\n",
    "# Example point\n",
    "point = np.array([1.0, 2.0])\n",
    "\n",
    "# Calculate the Jacobian matrix at the example point\n",
    "J = jacobian(point)\n",
    "\n",
    "print(\"Jacobian matrix at point\", point, \":\\n\", J)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Properties and Applications\n",
    "\n",
    "1. **Determinant of the Jacobian Matrix (Jacobian Determinant)**:\n",
    "   The determinant of the Jacobian matrix can be used to measure how much the function stretches or shrinks space near a point.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian determinant at point [1. 2.] : -9.999999999999993\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Calculate the determinant of the Jacobian matrix\n",
    "jacobian_determinant = np.linalg.det(J)\n",
    "\n",
    "print(\"Jacobian determinant at point\", point, \":\", jacobian_determinant)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Applications in Change of Variables for Multiple Integrals**:\n",
    "   The Jacobian determinant is used when changing variables in multiple integrals.\n",
    "\n",
    "3. **Use in Optimization Problems (Gradient and Hessian Matrices)**:\n",
    "   The gradient is the Jacobian of a scalar-valued function, and the Hessian matrix is the Jacobian of the gradient (second-order partial derivatives).\n",
    "\n",
    "**Gradient Example**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f at point [1. 2.] : [ 4. 13.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a scalar function\n",
    "def f(vars):\n",
    "    x, y = vars\n",
    "    return x**2 * y + y**3\n",
    "\n",
    "# Create a gradient function using numdifftools\n",
    "gradient = nd.Gradient(f)\n",
    "\n",
    "# Calculate the gradient at the example point\n",
    "grad = gradient(point)\n",
    "\n",
    "print(\"Gradient of f at point\", point, \":\", grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hessian matrix at point [1. 2.] :\n",
      " [[ 4.  2.]\n",
      " [ 2. 12.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a Hessian function using numdifftools\n",
    "hessian = nd.Hessian(f)\n",
    "\n",
    "# Calculate the Hessian matrix at the example point\n",
    "H = hessian(point)\n",
    "\n",
    "print(\"Hessian matrix at point\", point, \":\\n\", H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "These examples demonstrate how to use NumPy and `numdifftools` to calculate Jacobian matrices, their determinants, and other related derivatives such as gradients and Hessians. These tools are essential for various applications in multivariable calculus, optimization, and change of variables in multiple integrals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Advanced Applications\n",
    "\n",
    "Now onto examples using NumPy and `numdifftools` for various advanced applications in nonlinear systems, differential equations, and machine learning.\n",
    "\n",
    "## a. Nonlinear Systems and Stability Analysis\n",
    "\n",
    "**Fixed Points and Stability**:\n",
    "A fixed point of a function $ \\mathbf{F} $ is a point $ \\mathbf{x} $ such that $ \\mathbf{F}(\\mathbf{x}) = \\mathbf{x} $. Stability analysis involves studying the behavior of the system near the fixed points.\n",
    "\n",
    "**Example**: Consider the nonlinear system $ \\mathbf{F}(x, y) = \\begin{bmatrix} x^2 - y \\\\ y^2 - x \\end{bmatrix} $.\n",
    "\n",
    "Using NumPy and `numdifftools`:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian matrix at fixed point [1. 1.] :\n",
      " [[ 2. -1.]\n",
      " [-1.  2.]]\n",
      "Eigenvalues of the Jacobian matrix: [3. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define the vector-valued function\n",
    "def F(vars):\n",
    "    x, y = vars\n",
    "    return np.array([x**2 - y, y**2 - x])\n",
    "\n",
    "# Find the fixed points (manually or using a root-finding algorithm)\n",
    "fixed_point = np.array([1.0, 1.0])  # Example fixed point\n",
    "\n",
    "# Create a Jacobian function using numdifftools\n",
    "jacobian = nd.Jacobian(F)\n",
    "\n",
    "# Calculate the Jacobian matrix at the fixed point\n",
    "J = jacobian(fixed_point)\n",
    "\n",
    "print(\"Jacobian matrix at fixed point\", fixed_point, \":\\n\", J)\n",
    "\n",
    "# Analyze the stability by examining the eigenvalues of the Jacobian matrix\n",
    "eigenvalues = np.linalg.eigvals(J)\n",
    "print(\"Eigenvalues of the Jacobian matrix:\", eigenvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained example: Population Dynamics\n",
    "\n",
    "**Context**:\n",
    "Consider a simple ecological model where we are studying the populations of two species, say rabbits (species X) and foxes (species Y), in a closed ecosystem. The populations of these species change over time due to births, deaths, and interactions between the species. \n",
    "\n",
    "We can model the population dynamics using a system of nonlinear equations. Let's denote the populations of rabbits and foxes at time $ t $ by $ x(t) $ and $ y(t) $ respectively. The interactions between these populations can be represented by the following system of differential equations:\n",
    "\n",
    "$$\n",
    "\\frac{dx}{dt} = x^2 - y\n",
    "$$\n",
    "$$\n",
    "\\frac{dy}{dt} = y^2 - x\n",
    "$$\n",
    "\n",
    "**Explanation**:\n",
    "\n",
    "- **Rabbits (X)**: The growth rate of the rabbit population is influenced by its current population squared $ x^2 $ (reflecting exponential growth when resources are abundant) minus the number of foxes $ y $ (since foxes predate on rabbits).\n",
    "- **Foxes (Y)**: The growth rate of the fox population is influenced by its current population squared $ y^2 $ (which might represent a breeding season effect) minus the number of rabbits $ x $ (reflecting the dependency on rabbits for food).\n",
    "\n",
    "**Fixed Points:**\n",
    "\n",
    "A fixed point is a situation where the populations do not change over time, meaning $ \\frac{dx}{dt} = 0 $ and $ \\frac{dy}{dt} = 0 $.\n",
    "\n",
    "To find fixed points, we solve:\n",
    "$$\n",
    "x^2 - y = 0 \\implies y = x^2\n",
    "$$\n",
    "$$\n",
    "y^2 - x = 0 \\implies x = y^2\n",
    "$$\n",
    "\n",
    "Substituting $ y = x^2 $ into $ x = y^2 $:\n",
    "$$\n",
    "x = (x^2)^2 \\implies x = x^4\n",
    "$$\n",
    "\n",
    "This equation has solutions $ x = 0 $ or $ x = 1 $. Correspondingly, the fixed points are:\n",
    "1. $ (x, y) = (0, 0) $\n",
    "2. $ (x, y) = (1, 1) $\n",
    "\n",
    "**Stability Analysis**:\n",
    "\n",
    "The stability of these fixed points tells us whether small perturbations in the populations will die out over time (stable) or grow (unstable).\n",
    "\n",
    "Using the Jacobian matrix:\n",
    "$$\n",
    "J = \\begin{bmatrix}\n",
    "\\frac{\\partial (x^2 - y)}{\\partial x} & \\frac{\\partial (x^2 - y)}{\\partial y} \\\\\n",
    "\\frac{\\partial (y^2 - x)}{\\partial x} & \\frac{\\partial (y^2 - x)}{\\partial y}\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix} 2x & -1 \\\\ -1 & 2y \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For the fixed point $ (1, 1) $:\n",
    "$$\n",
    "J = \\begin{bmatrix} 2 \\cdot 1 & -1 \\\\ -1 & 2 \\cdot 1 \\end{bmatrix}\n",
    "= \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The eigenvalues of this matrix determine the stability. If the real parts of the eigenvalues are negative, the fixed point is stable. For our example, the eigenvalues of the Jacobian matrix at $ (1, 1) $ are:\n",
    "\n",
    "$$\n",
    "\\lambda = 2 \\pm 1\n",
    "$$\n",
    "\n",
    "So, the eigenvalues are $ \\lambda_1 = 3 $ and $ \\lambda_2 = 1 $, which are both positive, indicating that the fixed point $ (1, 1) $ is unstable.\n",
    "\n",
    "**Interpretation**:\n",
    "\n",
    "- **Fixed Point (1, 1)**: Imagine an ecosystem where there is exactly one rabbit and one fox. In this specific scenario, the populations remain constant if left undisturbed.\n",
    "- **Stability**: However, if there is a small increase or decrease in the population of rabbits or foxes, the system does not return to the original state. Instead, the populations will change further, indicating instability. This could mean that if there are slightly more rabbits, they might rapidly multiply until resources are exhausted, or if there are slightly more foxes, they might over-predate and then starve.\n",
    "\n",
    "**Real-World Significance**:\n",
    "\n",
    "Understanding fixed points and their stability in population dynamics helps ecologists predict the long-term behavior of species in an ecosystem. This knowledge is crucial for wildlife conservation and management, as it can inform strategies to maintain balanced populations and prevent the extinction or overpopulation of certain species."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Differential Equations\n",
    "\n",
    "**Systems of Differential Equations**:\n",
    "Systems of differential equations can be analyzed using the Jacobian matrix to understand the system's behavior around equilibrium points.\n",
    "\n",
    "**Example**: Consider the system of differential equations given by:\n",
    "$$\n",
    "\\frac{dx}{dt} = x^2 - y\n",
    "$$\n",
    "$$\n",
    "\\frac{dy}{dt} = y^2 - x\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian matrix at equilibrium point [1. 1.] :\n",
      " [[ 2. -1.]\n",
      " [-1.  2.]]\n",
      "Eigenvalues of the Jacobian matrix: [3. 1.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define the vector-valued function representing the system of differential equations\n",
    "def F(vars):\n",
    "    x, y = vars\n",
    "    return np.array([x**2 - y, y**2 - x])\n",
    "\n",
    "# Find an equilibrium point (manually or using a root-finding algorithm)\n",
    "equilibrium_point = np.array([1.0, 1.0])  # Example equilibrium point\n",
    "\n",
    "# Create a Jacobian function using numdifftools\n",
    "jacobian = nd.Jacobian(F)\n",
    "\n",
    "# Calculate the Jacobian matrix at the equilibrium point\n",
    "J = jacobian(equilibrium_point)\n",
    "\n",
    "print(\"Jacobian matrix at equilibrium point\", equilibrium_point, \":\\n\", J)\n",
    "\n",
    "# Perform phase plane analysis by examining the eigenvalues of the Jacobian matrix\n",
    "eigenvalues = np.linalg.eigvals(J)\n",
    "print(\"Eigenvalues of the Jacobian matrix:\", eigenvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained Example: Predator-Prey Model (Lotka-Volterra Equations)\n",
    "\n",
    "**Introduction**:\n",
    "Another take on the predator-prey model is to use the Lotka-Volterra equations. Read the following example and compare it with the previous example on nonlinear systems and stability analysis.\n",
    "\n",
    "**Context**:\n",
    "The Lotka-Volterra equations describe the dynamics of biological systems in which two species interact, one as a predator and the other as prey. This model helps ecologists understand the population dynamics and predict the long-term behavior of these species in an ecosystem.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "The Lotka-Volterra equations are a pair of first-order, nonlinear differential equations given by:\n",
    "\n",
    "$$\n",
    "\\frac{dx}{dt} = \\alpha x - \\beta xy\n",
    "$$\n",
    "$$\n",
    "\\frac{dy}{dt} = \\delta xy - \\gamma y\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ x(t) $ is the number of prey (e.g., rabbits).\n",
    "- $ y(t) $ is the number of predators (e.g., foxes).\n",
    "- $ \\alpha $ is the natural growth rate of prey in the absence of predators.\n",
    "- $ \\beta $ is the natural dying rate of prey due to predation.\n",
    "- $ \\gamma $ is the natural dying rate of predators in the absence of prey.\n",
    "- $ \\delta $ is the factor describing how many prey are turned into predators.\n",
    "\n",
    "**System Description:**\n",
    "\n",
    "Let's consider:\n",
    "- $\\alpha = 1.0$\n",
    "- $\\beta = 0.1$\n",
    "- $\\gamma = 1.5$\n",
    "- $\\delta = 0.075$\n",
    "\n",
    "**Equilibrium Points:**\n",
    "\n",
    "To find the equilibrium points, set the derivatives to zero and solve for $ x $ and $ y $:\n",
    "\n",
    "$$\n",
    "\\alpha x - \\beta xy = 0 \\quad \\Rightarrow \\quad x(\\alpha - \\beta y) = 0\n",
    "$$\n",
    "$$\n",
    "\\delta xy - \\gamma y = 0 \\quad \\Rightarrow \\quad y(\\delta x - \\gamma) = 0\n",
    "$$\n",
    "\n",
    "From these, we get two equilibrium points:\n",
    "1. $ (x, y) = (0, 0) $\n",
    "2. $ (x, y) = \\left(\\frac{\\gamma}{\\delta}, \\frac{\\alpha}{\\beta}\\right) = \\left(\\frac{1.5}{0.075}, \\frac{1.0}{0.1}\\right) = (20, 10) $\n",
    "\n",
    "**Stability Analysis Using Jacobian:**\n",
    "\n",
    "The Jacobian matrix $ J $ of the system is:\n",
    "\n",
    "$$\n",
    "J = \\begin{bmatrix} \\alpha - \\beta y & -\\beta x \\\\ \\delta y & \\delta x - \\gamma \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "**Using NumPy and numdifftools:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jacobian matrix at equilibrium point [20. 10.] :\n",
      " [[ 0.   -2.  ]\n",
      " [ 0.75  0.  ]]\n",
      "Eigenvalues of the Jacobian matrix: [0.+1.22474487j 0.-1.22474487j]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define the predator-prey system of equations\n",
    "def F(vars):\n",
    "    x, y = vars\n",
    "    dxdt = 1.0 * x - 0.1 * x * y\n",
    "    dydt = 0.075 * x * y - 1.5 * y\n",
    "    return np.array([dxdt, dydt])\n",
    "\n",
    "# Calculate the Jacobian matrix at the equilibrium point (20, 10)\n",
    "equilibrium_point = np.array([20.0, 10.0])\n",
    "\n",
    "# Create a Jacobian function using numdifftools\n",
    "jacobian = nd.Jacobian(F)\n",
    "\n",
    "# Calculate the Jacobian matrix at the equilibrium point\n",
    "J = jacobian(equilibrium_point)\n",
    "\n",
    "print(\"Jacobian matrix at equilibrium point\", equilibrium_point, \":\\n\", J)\n",
    "\n",
    "# Analyze the stability by examining the eigenvalues of the Jacobian matrix\n",
    "eigenvalues = np.linalg.eigvals(J)\n",
    "print(\"Eigenvalues of the Jacobian matrix:\", eigenvalues)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Interpretation of Results:**\n",
    "\n",
    "- **Eigenvalues**: The eigenvalues determine the stability of the equilibrium point. If the real parts of the eigenvalues are negative, the equilibrium point is stable. If any real parts are positive, the equilibrium point is unstable.\n",
    "\n",
    "**Practical Significance:**\n",
    "\n",
    "Understanding the stability of equilibrium points in predator-prey models has several practical applications:\n",
    "\n",
    "1. **Wildlife Management**: Ecologists can use these models to predict the outcomes of introducing new species into an ecosystem or changing the population of existing species. This helps in making informed decisions to maintain ecological balance.\n",
    "   \n",
    "2. **Conservation Efforts**: By understanding the dynamics and stability of species populations, conservationists can develop strategies to protect endangered species or control overpopulated species.\n",
    "\n",
    "3. **Agricultural Planning**: Farmers can use predator-prey models to plan biological pest control strategies, introducing natural predators to manage pest populations effectively.\n",
    "\n",
    "**Real-World Example:**\n",
    "\n",
    "Consider a wildlife reserve with a population of rabbits (prey) and foxes (predators). By applying the Lotka-Volterra model, ecologists can predict how the populations will evolve over time. For instance, if the number of rabbits suddenly increases due to favorable conditions, the model can help predict how the fox population will respond and whether the system will return to equilibrium or if one species will outcompete the other. This information is crucial for maintaining the health and balance of the ecosystem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Machine Learning and Data Science\n",
    "\n",
    "**Backpropagation in Neural Networks**:\n",
    "Backpropagation involves computing the gradients of the loss function with respect to the network's weights. This can be done using the Jacobian matrix.\n",
    "\n",
    "**Example**: Simple neural network with one layer and a quadratic loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the loss with respect to weights at W: [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a simple neural network function\n",
    "def neural_network(W, x):\n",
    "    return np.dot(W, x)\n",
    "\n",
    "# Define the loss function\n",
    "def loss(W, x, y_true):\n",
    "    y_pred = neural_network(W, x)\n",
    "    return np.sum((y_pred - y_true)**2)\n",
    "\n",
    "# Input and target values\n",
    "x = np.array([1.0, 2.0])\n",
    "y_true = np.array([3.0])\n",
    "\n",
    "# Initial weights\n",
    "W = np.array([[1.0, 1.0]])\n",
    "\n",
    "# Create a gradient function using numdifftools for the loss with respect to weights\n",
    "gradient = nd.Gradient(lambda W: loss(W, x, y_true))\n",
    "\n",
    "# Calculate the gradient at the initial weights\n",
    "grad = gradient(W)\n",
    "\n",
    "print(\"Gradient of the loss with respect to weights at W:\", grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Optimization Algorithms (e.g., Newton's Method)**:\n",
    "Newton's method involves using the gradient and Hessian to find the minimum of a function.\n",
    "\n",
    "**Example**: Finding the minimum of a scalar function.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient at x0: [3. 5.]\n",
      "Hessian at x0:\n",
      " [[2. 1.]\n",
      " [1. 4.]]\n",
      "Next iteration point x1: [1.33226763e-15 4.44089210e-16]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define a scalar function\n",
    "def f(x):\n",
    "    return x[0]**2 + 2*x[1]**2 + x[0]*x[1]\n",
    "\n",
    "# Create gradient and Hessian functions using numdifftools\n",
    "gradient = nd.Gradient(f)\n",
    "hessian = nd.Hessian(f)\n",
    "\n",
    "# Initial guess\n",
    "x0 = np.array([1.0, 1.0])\n",
    "\n",
    "# Perform one step of Newton's method\n",
    "grad = gradient(x0)\n",
    "H = hessian(x0)\n",
    "H_inv = np.linalg.inv(H)\n",
    "x1 = x0 - np.dot(H_inv, grad)\n",
    "\n",
    "print(\"Gradient at x0:\", grad)\n",
    "print(\"Hessian at x0:\\n\", H)\n",
    "print(\"Next iteration point x1:\", x1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained Example: Backpropagation in Neural Networks for Image Classification\n",
    "\n",
    "**Context**:\n",
    "Imagine you are building a simple neural network to classify images of handwritten digits (like the famous MNIST dataset). The neural network needs to learn from a set of labeled images to correctly identify digits in new images. The process of training the neural network involves adjusting its weights to minimize the difference between its predictions and the actual labels. This adjustment is done using a technique called backpropagation, which relies on the calculation of gradients.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "In a neural network, the weights determine how input signals are transformed as they pass through the network. During training, the network makes predictions, calculates the error (loss), and then adjusts the weights to reduce this error. This adjustment is done by computing the gradient of the loss function with respect to each weight, which tells us how to change the weights to reduce the loss.\n",
    "\n",
    "**Simple Neural Network Example:**\n",
    "\n",
    "Consider a very simple neural network with one layer:\n",
    "\n",
    "- Input layer with 2 neurons (features of the image)\n",
    "- Output layer with 1 neuron (predicted digit)\n",
    "\n",
    "Let:\n",
    "- $ x $ be the input vector (e.g., pixel values of the image).\n",
    "- $ W $ be the weights matrix.\n",
    "- $ y $ be the true label (actual digit).\n",
    "- $ \\hat{y} $ be the predicted label.\n",
    "\n",
    "The neural network's prediction can be modeled as:\n",
    "$$\n",
    "\\hat{y} = W \\cdot x\n",
    "$$\n",
    "\n",
    "The loss function (mean squared error) is:\n",
    "$$\n",
    "L(W) = \\frac{1}{2} (\\hat{y} - y)^2\n",
    "$$\n",
    "\n",
    "**Using NumPy and numdifftools for Backpropagation:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of the loss with respect to weights at W: [-0.325 -0.975]\n",
      "Updated weights after one step: [0.10325 0.20975]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numdifftools as nd\n",
    "\n",
    "# Define the neural network function\n",
    "def neural_network(W, x):\n",
    "    return np.dot(W, x)\n",
    "\n",
    "# Define the loss function\n",
    "def loss(W, x, y_true):\n",
    "    y_pred = neural_network(W, x)\n",
    "    return 0.5 * np.sum((y_pred - y_true)**2)\n",
    "\n",
    "# Input vector (e.g., pixel values of the image)\n",
    "x = np.array([0.5, 1.5])\n",
    "\n",
    "# True label (actual digit)\n",
    "y_true = np.array([1.0])\n",
    "\n",
    "# Initial weights\n",
    "W = np.array([0.1, 0.2])\n",
    "\n",
    "# Create a gradient function using numdifftools for the loss with respect to weights\n",
    "gradient = nd.Gradient(lambda W: loss(W, x, y_true))\n",
    "\n",
    "# Calculate the gradient at the initial weights\n",
    "grad = gradient(W)\n",
    "\n",
    "print(\"Gradient of the loss with respect to weights at W:\", grad)\n",
    "\n",
    "# Update weights (simple gradient descent step)\n",
    "learning_rate = 0.01\n",
    "W_new = W - learning_rate * grad\n",
    "\n",
    "print(\"Updated weights after one step:\", W_new)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpretation**:\n",
    "\n",
    "1. **Neural Network Prediction**: The network takes in features of the image (e.g., pixel values) and produces a prediction. Initially, the weights (parameters) of the network are set randomly.\n",
    "   \n",
    "2. **Loss Calculation**: The loss function measures how far the network's prediction is from the actual label (the correct digit). The goal is to minimize this loss.\n",
    "   \n",
    "3. **Gradient Calculation**: The gradient tells us how to adjust each weight to reduce the loss. Think of it as a way to find the slope of the loss function – it points in the direction where the loss decreases the fastest.\n",
    "   \n",
    "4. **Weight Update**: By updating the weights in the direction of the negative gradient (downhill), we improve the network's predictions. This process is repeated many times with many images, gradually making the network better at classifying digits.\n",
    "\n",
    "**Practical Significance:**\n",
    "\n",
    "Understanding backpropagation and gradient calculation is crucial for training neural networks, which are widely used in various applications:\n",
    "\n",
    "1. **Image Recognition**: Neural networks are used in facial recognition systems, object detection, and medical image analysis.\n",
    "   \n",
    "2. **Natural Language Processing**: They help in tasks like sentiment analysis, language translation, and chatbots.\n",
    "   \n",
    "3. **Autonomous Vehicles**: Neural networks process data from sensors and cameras to help vehicles navigate.\n",
    "\n",
    "**Real-World Example:**\n",
    "\n",
    "Consider an app that recognizes handwritten numbers from photos, such as a digit recognition feature in a banking app for check processing. By training a neural network using backpropagation, the app learns to accurately identify digits, even with different handwriting styles, improving the user experience and automating the process of digitizing handwritten information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explained Example 2: Predicting Optimal Trading Strategy in a Pseudo-Random Walk\n",
    "\n",
    "A different example that involves predicting a pseudo-random walk, which can be analogous to stock market simulation.\n",
    "\n",
    "**Context**:\n",
    "Imagine you are trying to predict the optimal trading strategy in a stock market where the price of a stock follows a pseudo-random walk. Your goal is to maximize your profit by deciding the optimal number of shares to buy or sell at each step, considering the constraints of the market and your budget.\n",
    "\n",
    "**Explanation:**\n",
    "\n",
    "A pseudo-random walk can be modeled as a sequence of prices that follow a random pattern with some underlying trend. We aim to optimize a trading strategy based on these price movements.\n",
    "\n",
    "**Define the Problem:**\n",
    "\n",
    "1. **Price (P)**: The price of the stock at each step.\n",
    "2. **Shares (S)**: The number of shares to buy or sell.\n",
    "3. **Profit (π)**: The profit based on the number of shares traded and the price difference.\n",
    "4. **Objective**: Maximize the total profit over a sequence of steps.\n",
    "\n",
    "**Simplified Model:**\n",
    "\n",
    "1. **Price Function (P)**: Modeled as a random walk with a drift.\n",
    "   $$\n",
    "   P(t+1) = P(t) + \\mu + \\sigma \\cdot Z_t\n",
    "   $$\n",
    "   where $\\mu$ is the drift, $\\sigma$ is the volatility, and $Z_t$ is a standard normal random variable.\n",
    "\n",
    "2. **Profit Function (π)**:\n",
    "   $$\n",
    "   \\pi(S, P) = S \\cdot (P_{t+1} - P_t)\n",
    "   $$\n",
    "\n",
    "3. **Objective Function**:\n",
    "   $$\n",
    "   \\text{Objective}(S) = \\sum_{t=0}^{T-1} \\pi(S, P)\n",
    "   $$\n",
    "\n",
    "**Using NumPy and numdifftools:**\n",
    "\n",
    "Here’s the code to simulate the pseudo-random walk and optimize the trading strategy:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of shares: 125.39331683535178\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Constants\n",
    "mu = 0.1    # Drift\n",
    "sigma = 0.2 # Volatility\n",
    "T = 50      # Number of time steps\n",
    "P0 = 100    # Initial price\n",
    "transaction_cost = 0.01  # Transaction cost per share\n",
    "risk_aversion = 0.01     # Stronger risk aversion penalty\n",
    "\n",
    "# Simulate the pseudo-random walk\n",
    "np.random.seed(42)  # For reproducibility\n",
    "Z = np.random.normal(size=T)\n",
    "P = np.zeros(T)\n",
    "P[0] = P0\n",
    "\n",
    "for t in range(1, T):\n",
    "    P[t] = P[t-1] + mu + sigma * Z[t-1]\n",
    "\n",
    "# Define the profit function including transaction costs\n",
    "def profit(S, P):\n",
    "    return S * (P[1:] - P[:-1]) - transaction_cost * np.abs(S)\n",
    "\n",
    "# Define the objective function to maximize total profit, including a risk penalty\n",
    "def objective(S, P):\n",
    "    total_profit = np.sum(profit(S, P))\n",
    "    risk_penalty = risk_aversion * S**2\n",
    "    return -(total_profit - risk_penalty)  # Negative because we minimize in scipy\n",
    "\n",
    "# Initial guess for shares\n",
    "S_initial = 1.0\n",
    "\n",
    "# Define constraints: shares should be within a realistic range\n",
    "constraints = (\n",
    "    {'type': 'ineq', 'fun': lambda S: S - 1},  # S >= 1\n",
    "    {'type': 'ineq', 'fun': lambda S: 1000 - S}  # S <= 1000\n",
    ")\n",
    "\n",
    "# Perform the optimization using scipy.optimize.minimize\n",
    "result = minimize(objective, S_initial, args=(P,), method='SLSQP', constraints=constraints)\n",
    "\n",
    "# Optimal number of shares\n",
    "optimal_shares = result.x[0]\n",
    "\n",
    "print(\"Optimal number of shares:\", optimal_shares)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**Interpretation**\n",
    "\n",
    "1. **Pseudo-Random Walk**:\n",
    "   - The price follows a random walk with drift \\(\\mu\\) and volatility \\(\\sigma\\).\n",
    "\n",
    "2. **Profit Function**:\n",
    "   - The profit is calculated based on the difference in prices and the number of shares traded.\n",
    "\n",
    "3. **Objective Function**:\n",
    "   - The total profit over all time steps is maximized.\n",
    "\n",
    "4. **Optimization**:\n",
    "   - Newton's method is used to find the optimal number of shares to maximize profit.\n",
    "\n",
    "**Practical Significance:**\n",
    "\n",
    "Understanding and predicting optimal trading strategies can be highly valuable in stock market trading. This model provides a simplified version of such an approach, helping traders make informed decisions based on price movements.\n",
    "\n",
    "By running this code, you should be able to simulate the pseudo-random walk of stock prices and find the optimal trading strategy in terms of the number of shares to trade at each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary**\n",
    "\n",
    "These examples demonstrate how to use NumPy and `numdifftools` for various advanced applications, including nonlinear systems and stability analysis, differential equations, and machine learning tasks such as backpropagation and optimization algorithms. These tools are essential for analyzing and solving complex problems in multivariable calculus and related fields."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of stock prices:\n",
      "[[100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.\n",
      "  100.         100.         100.         100.         100.        ]\n",
      " [101.09342831  99.8234714  101.39537708 103.14605971  99.63169325\n",
      "   99.63172609 103.25842563 101.63486946  99.16105123 101.18512009\n",
      "   99.17316461  99.16854049 100.58392454  96.27343951  96.65016433\n",
      "   98.97542494  98.07433776 100.72849467  98.28395185  97.2753926\n",
      "  103.03129754  99.6484474  100.23505641  97.25050363  99.01123455\n",
      "  100.32184518  97.79801285 100.85139604  98.89872262  99.5166125\n",
      "   98.89658678 103.80455637 100.07300555  97.98457814 101.74508982\n",
      "   97.6583127  100.51772719  96.18065975  97.4436279  100.49372247\n",
      "  101.57693316 100.44273656  99.86870344  99.49779261  97.14295602\n",
      "   98.66031158  99.17872246 102.21424445 100.78723658  96.57391969]\n",
      " [101.84977692  99.15448987 100.12403722 104.51104575 101.78572951\n",
      "  101.58705873 101.62855845 101.10796914  99.91718088 103.26051822\n",
      "   98.32191327  98.89947844  98.4589182   94.06645443  98.31742958\n",
      "  101.75908903  98.0311652  102.85091032  99.09309615  96.11758244\n",
      "  103.87903    102.81335496 100.26347096 100.3910018   93.92256185\n",
      "  102.07126254  98.06607146 100.34914126  99.17912181  95.6602066\n",
      "   98.56098736 104.64975917 103.13102453  97.06691295 100.20162983\n",
      "   96.77595609 102.45852772  96.90923038  96.50863641 101.62581929\n",
      "  101.87572689 102.48904637  98.56630949  98.9452572   96.47828807\n",
      "   95.87115508  99.8652778  102.85013005 100.89833124  96.21739363]\n",
      " [ 99.06852281  98.41946691  99.53788204 102.93862007 101.55918356\n",
      "  102.50957255 105.56399409 101.56210127 100.53177224 103.21003227\n",
      "   94.64709004  98.94593375  98.67598114  98.79468992  98.0374983\n",
      "  102.47455178  98.06113966 100.54976923 101.45710627  97.65917973\n",
      "  105.62634166 101.04622482 103.17671497  97.67672815  95.11886684\n",
      "  106.64498523  96.22137741  99.31294058  99.47596763  94.79261511\n",
      "   95.60284997 104.8979109  101.04302615  98.08338296  98.45927532\n",
      "   99.87265972 100.95596667  96.38192494  98.17537379  99.22569322\n",
      "  102.44105554 105.2708917   95.496002    99.40957534  97.0762273\n",
      "   97.46611147  97.49457455 100.23679749 102.05249023  96.88511285]\n",
      " [ 99.66391047  99.19983134  98.28365551 103.51971619 102.25602677\n",
      "  101.14752495 109.60873028 102.62613271  98.23702698 104.66850068\n",
      "   92.89672145 100.6024561  101.06116823  97.27190351 100.02447551\n",
      "  103.42301714  99.77144392 104.46476094 101.06063601  96.2846538\n",
      "  103.8528449   99.49858005 103.12078966  98.44085705  95.74035601\n",
      "  108.51592912  96.34261999 102.29934839  99.04890371 100.0444467\n",
      "   96.89476446 103.20452807  98.9799448   99.12791688  98.11769492\n",
      "  101.39871495 102.01244587  96.33791905  96.61086337  96.31868359\n",
      "  101.62866733 107.17923989  96.00039994  97.03221766  97.50953855\n",
      "   98.31468531  95.86864303 100.64521253 102.27334961  94.76726183]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Constants\n",
    "num_stocks = 50\n",
    "num_days = 90\n",
    "mu = 0.001    # Drift\n",
    "sigma = 0.02  # Volatility\n",
    "initial_price = 100\n",
    "\n",
    "# Simulate the stock prices\n",
    "np.random.seed(42)  # For reproducibility\n",
    "stock_prices = np.zeros((num_days, num_stocks))\n",
    "stock_prices[0] = initial_price\n",
    "\n",
    "for t in range(1, num_days):\n",
    "    Z = np.random.normal(mu, sigma, num_stocks)\n",
    "    stock_prices[t] = stock_prices[t-1] * (1 + Z)\n",
    "\n",
    "# Display the first few rows of the stock prices\n",
    "print(\"First few rows of stock prices:\")\n",
    "print(stock_prices[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected stocks and shares to buy:\n",
      "{'Stocks': array([ 0,  1,  3,  4,  5,  6,  7,  8,  9, 11, 12, 14, 15, 16, 17, 19, 20,\n",
      "       21, 22, 24, 25, 26, 27, 28, 29, 30, 33, 34, 35, 37, 38, 40, 41, 42,\n",
      "       45, 48, 49]), 'Shares': array([272.63592715, 201.06552054, 232.88600816, 273.4135593 ,\n",
      "       251.85335601, 259.14098494, 206.72004922, 264.1011169 ,\n",
      "       156.77154825, 221.13529071, 229.85272512, 181.11213649,\n",
      "       239.66762173, 263.59320939, 264.85022598, 210.23694829,\n",
      "       177.7092698 , 237.88126638, 255.64708909, 216.74935545,\n",
      "       269.39170525, 271.34380246, 202.79554164, 221.34143781,\n",
      "       209.51762039, 271.75639402, 248.74179185, 241.17089383,\n",
      "       231.95341451, 272.77276342, 254.44625921, 244.95839313,\n",
      "       238.94483384, 241.90533314, 256.10266817, 190.6377462 ,\n",
      "       256.7418603 ])}\n"
     ]
    }
   ],
   "source": [
    "# Analyze the first 60 days to determine which stocks have a positive trend\n",
    "look_back_days = 60\n",
    "stock_prices_lookback = stock_prices[:look_back_days]\n",
    "\n",
    "# Calculate daily returns\n",
    "daily_returns = np.diff(stock_prices_lookback, axis=0) / stock_prices_lookback[:-1]\n",
    "\n",
    "# Calculate the mean daily return and standard deviation of returns\n",
    "mean_returns = np.mean(daily_returns, axis=0)\n",
    "std_returns = np.std(daily_returns, axis=0)\n",
    "\n",
    "# Select stocks with positive mean returns\n",
    "selected_stocks = np.where(mean_returns > 0)[0]\n",
    "\n",
    "# Starting capital\n",
    "starting_capital = 1000000  # 1 million dollars\n",
    "\n",
    "# Calculate the amount to invest in each selected stock\n",
    "investment_per_stock = starting_capital / len(selected_stocks)\n",
    "\n",
    "# Calculate the number of shares to buy for each selected stock\n",
    "num_shares = investment_per_stock / stock_prices_lookback[-1][selected_stocks]\n",
    "\n",
    "# Display the selected stocks and the number of shares to buy\n",
    "portfolio = {'Stocks': selected_stocks, 'Shares': num_shares}\n",
    "print(\"Selected stocks and shares to buy:\")\n",
    "print(portfolio)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio value over the validation period: [ 996630.42894352  991965.00030287  993057.8064657   993068.75420729\n",
      "  991328.52764324  995150.82699241  999150.08973125 1004925.03535697\n",
      " 1002250.975706   1005735.46322646 1003434.23583195 1003415.74552708\n",
      " 1005259.6802283  1002718.83698544 1007940.88394597 1013681.86814506\n",
      " 1008042.4133047  1002517.51342487 1002385.418666   1004387.35268628\n",
      " 1005786.36139822 1001248.19403995 1000597.5320686  1002521.12358947\n",
      " 1001808.70334056  996713.17843555  995804.38883986  996611.47596222\n",
      "  997410.49682047  995268.81075253]\n"
     ]
    }
   ],
   "source": [
    "import numdifftools as nd\n",
    "\n",
    "# Define the profit function\n",
    "def profit(S, P, shares):\n",
    "    return shares * (P[1:] - P[:-1])\n",
    "\n",
    "# Define the objective function to maximize total profit\n",
    "def objective(shares, P):\n",
    "    total_profit = np.sum(profit(shares, P, shares))\n",
    "    return -total_profit  # Negative because we minimize in scipy\n",
    "\n",
    "# Use the next 30 days to validate the investment strategy\n",
    "validation_days = 30\n",
    "stock_prices_validation = stock_prices[look_back_days:look_back_days + validation_days]\n",
    "\n",
    "# Calculate the Jacobian matrix for the objective function\n",
    "def portfolio_value(shares, P):\n",
    "    values = np.zeros(len(P) - 1)\n",
    "    for t in range(len(P) - 1):\n",
    "        values[t] = np.sum(shares * (P[t+1] - P[t]))\n",
    "    return values\n",
    "\n",
    "# Initial shares based on selected stocks\n",
    "initial_shares = num_shares\n",
    "\n",
    "# Jacobian function using numdifftools\n",
    "jacobian_func = nd.Jacobian(lambda shares: portfolio_value(shares, stock_prices_validation[:, selected_stocks]))\n",
    "\n",
    "# Perform optimization using the Jacobian\n",
    "def optimize_portfolio(jacobian_func, initial_shares, max_iter=100, tol=1e-6):\n",
    "    shares = initial_shares.copy()\n",
    "    for _ in range(max_iter):\n",
    "        jacobian = jacobian_func(shares)\n",
    "        grad = np.sum(jacobian, axis=0)  # Gradient is the sum of the Jacobian columns\n",
    "        step = grad / np.linalg.norm(grad)\n",
    "        new_shares = shares + step\n",
    "        if np.linalg.norm(new_shares - shares) < tol:\n",
    "            break\n",
    "        shares = new_shares\n",
    "    return shares\n",
    "\n",
    "# Optimize the portfolio\n",
    "optimized_shares = optimize_portfolio(jacobian_func, initial_shares)\n",
    "\n",
    "# Calculate the portfolio value over the validation period\n",
    "portfolio_value_validation = np.zeros(validation_days)\n",
    "for t in range(validation_days):\n",
    "    portfolio_value_validation[t] = np.sum(optimized_shares * stock_prices_validation[t, selected_stocks])\n",
    "\n",
    "print(\"Portfolio value over the validation period:\", portfolio_value_validation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New portfolio value over the additional period: [ 995268.81075253  994576.34617779  995302.36087053  999123.96969627\n",
      "  996347.14459282  998075.32168775 1000843.09483399  997402.93956957\n",
      "  998318.64945591 1001155.74591646 1006190.99168758 1006789.02395486\n",
      " 1008079.7665531  1009303.31192555 1012431.92215136 1010416.86996835\n",
      " 1017388.51387695 1017559.54497421 1013042.8008824  1010620.35708126\n",
      " 1005473.68299519 1007323.04977436 1009549.83268672 1008081.90800397\n",
      " 1006354.03295826 1006465.25160802 1002679.48693783  999625.47515495\n",
      "  999148.96153675  990655.63741579]\n"
     ]
    }
   ],
   "source": [
    "# Generate an additional 30 days of stock data\n",
    "additional_days = 30\n",
    "new_stock_prices = np.zeros((additional_days, num_stocks))\n",
    "new_stock_prices[0] = stock_prices[-1]\n",
    "\n",
    "for t in range(1, additional_days):\n",
    "    Z = np.random.normal(mu, sigma, num_stocks)\n",
    "    new_stock_prices[t] = new_stock_prices[t-1] * (1 + Z)\n",
    "\n",
    "# Simulate the investment strategy with the new data\n",
    "new_portfolio_value = np.zeros(additional_days)\n",
    "for t in range(additional_days):\n",
    "    new_portfolio_value[t] = np.sum(optimized_shares * new_stock_prices[t, selected_stocks])\n",
    "\n",
    "print(\"New portfolio value over the additional period:\", new_portfolio_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings over the additional 30-day period: -4613.173336733715\n"
     ]
    }
   ],
   "source": [
    "# Calculate earnings over the additional period\n",
    "earnings = new_portfolio_value[-1] - new_portfolio_value[0]\n",
    "\n",
    "print(\"Earnings over the additional 30-day period:\", earnings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: Deep dive on matrix decomposition methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If  $ A = \\begin{bmatrix} a & b & c & d \\\\ e & f & g & h \\\\ i & j & k & l \\\\ m & n & o & p \\end{bmatrix} $ then the determinant $$ |A| = $$ \n",
    "$$ a(f(kp−lo)−g(jp−ln)+h(jo−kn))−b(e(kp−lo)−g(ip−lm)+h(io−km))+c(e(jp−ln)−f(ip−lm)+h(in−jm))−d(e(jo−kn)−f(io−km)+g(in−jm)) $$\n",
    "\n",
    "As $ 4 x 4$ is a bit daunting, here is the breakdown:\n",
    "\n",
    "To calculate the determinant of a $4 \\times 4$ matrix containing the letters $a$ to $o$, the general process involves expanding the determinant along a row or column using the method of cofactors. Given a matrix:\n",
    "\n",
    "\n",
    "\\begin{pmatrix}\n",
    "a & b & c & d \\\\\n",
    "e & f & g & h \\\\\n",
    "i & j & k & l \\\\\n",
    "m & n & o & p \\\\\n",
    "\\end{pmatrix}\n",
    "\n",
    "The determinant of this matrix, denoted as $\\det(A)$, is calculated as follows:\n",
    "\n",
    "1. Choose a row or column to expand along. For simplicity, let's expand along the first row.\n",
    "\n",
    "2. Apply the formula for the determinant of a $4 \\times 4$ matrix:\n",
    "\n",
    "$$\n",
    "\\det(A) = a \\cdot \\det(M_{11}) - b \\cdot \\det(M_{12}) + c \\cdot \\det(M_{13}) - d \\cdot \\det(M_{14})\n",
    "$$\n",
    "\n",
    "where $M_{ij}$ is the $3 \\times 3$ minor matrix obtained by removing the $i$-th row and $j$-th column.\n",
    "\n",
    "So, we need to find the determinants of the $3 \\times 3$ minors:\n",
    "\n",
    "$$\n",
    "M_{11} = \\begin{pmatrix}\n",
    "f & g & h \\\\\n",
    "j & k & l \\\\\n",
    "n & o & p \\\\\n",
    "\\end{pmatrix},\n",
    "M_{12} = \\begin{pmatrix}\n",
    "e & g & h \\\\\n",
    "i & k & l \\\\\n",
    "m & o & p \\\\\n",
    "\\end{pmatrix},\n",
    "M_{13} = \\begin{pmatrix}\n",
    "e & f & h \\\\\n",
    "i & j & l \\\\\n",
    "m & n & p \\\\\n",
    "\\end{pmatrix},\n",
    "M_{14} = \\begin{pmatrix}\n",
    "e & f & g \\\\\n",
    "i & j & k \\\\\n",
    "m & n & o \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Next, calculate the determinants of each $3 \\times 3$ minor matrix using the formula for the determinant of a $3 \\times 3$ matrix:\n",
    "\n",
    "$$ \\det \\begin{pmatrix}\n",
    "a & b & c \\\\\n",
    "d & e & f \\\\\n",
    "g & h & i \\\\\n",
    "\\end{pmatrix} = a(ei - fh) - b(di - fg) + c(dh - eg)\n",
    "$$\n",
    "\n",
    "Applying this formula, we get:\n",
    "\n",
    "$$\n",
    "\\det(M_{11}) = f(kp - lo) - g(jp - ln) + h(jo - kn)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\det(M_{12}) = e(kp - lo) - g(ip - lm) + h(io - km)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\det(M_{13}) = e(jp - ln) - f(ip - lm) + h(in - jm)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\det(M_{14}) = e(jo - kn) - f(io - km) + g(in - jm)\n",
    "$$\n",
    "\n",
    "Finally, substitute these back into the original expansion:\n",
    "\n",
    "$$\n",
    "\\det(A) = a(f(kp - lo) - g(jp - ln) + h(jo - kn)) - b(e(kp - lo) - g(ip - lm) + h(io - km)) + c(e(jp - ln) - f(ip - lm) + h(in - jm)) - d(e(jo - kn) - f(io - km) + g(in - jm))\n",
    "$$\n",
    "\n",
    "This expression represents the determinant of the original $4 \\times 4$ matrix in terms of its entries $a$ through $p$.\n",
    "\n",
    "As the \"cofactor expansion\" (recursion) requires a factorial number of calculations, the method is computationally very inefficient. Nonetheless, here is a general outline of the process for an $n \\times n$ matrix:\n",
    "\n",
    "1. **Choose a Row or Column**: Select a row or column to expand along. This is often done for simplicity, and some rows or columns may be easier to work with (e.g., those with zeros).\n",
    "\n",
    "2. **Calculate Cofactors**: For each element in the chosen row or column, calculate the cofactor. The cofactor $C_{ij}$ of an element $a_{ij}$ is given by:\n",
    "\n",
    "   $$\n",
    "   C_{ij} = (-1)^{i+j} \\det(M_{ij})\n",
    "   $$\n",
    "\n",
    "   where $M_{ij}$ is the $(n-1) \\times (n-1)$ minor matrix obtained by removing the $i$-th row and $j$-th column.\n",
    "\n",
    "3. **Expand the Determinant**: Use the cofactor expansion formula to calculate the determinant:\n",
    "\n",
    "   $$\n",
    "   \\det(A) = \\sum_{j=1}^{n} a_{ij} C_{ij}\n",
    "   $$\n",
    "\n",
    "   or equivalently,\n",
    "\n",
    "   $$\n",
    "   \\det(A) = \\sum_{i=1}^{n} a_{ij} C_{ij}\n",
    "   $$\n",
    "\n",
    "   depending on whether you expand along a row or a column.\n",
    "\n",
    "4. **Recursively Apply the Process**: For each $(n-1) \\times (n-1)$ minor matrix, recursively apply the same process until you reach $2 \\times 2$ matrices, which are simple to compute:\n",
    "\n",
    "   $$\n",
    "   \\det \\begin{pmatrix}\n",
    "   a & b \\\\\n",
    "   c & d \\\\\n",
    "   \\end{pmatrix} = ad - bc\n",
    "   $$\n",
    "\n",
    "### Example \n",
    "\n",
    "Consider a $5 \\times 5$ matrix \\(A\\):\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "a & b & c & d & e \\\\\n",
    "f & g & h & i & j \\\\\n",
    "k & l & m & n & o \\\\\n",
    "p & q & r & s & t \\\\\n",
    "u & v & w & x & y \\\\\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "1. **Choose a row or column**: Let's expand along the first row.\n",
    "\n",
    "2. **Calculate Cofactors**:\n",
    "   - For $a$, the minor matrix $M_{11}$ is:\n",
    "\n",
    "     $$\n",
    "     M_{11} = \\begin{pmatrix}\n",
    "     g & h & i & j \\\\\n",
    "     l & m & n & o \\\\\n",
    "     q & r & s & t \\\\\n",
    "     v & w & x & y \\\\\n",
    "     \\end{pmatrix}\n",
    "     $$\n",
    "\n",
    "   - Similarly, calculate the minors for $b, c, d, e$.\n",
    "\n",
    "3. **Expand the Determinant**:\n",
    "   $$\n",
    "   \\det(A) = a \\cdot \\det(M_{11}) - b \\cdot \\det(M_{12}) + c \\cdot \\det(M_{13}) - d \\cdot \\det(M_{14}) + e \\cdot \\det(M_{15})\n",
    "   $$\n",
    "\n",
    "4. **Recursively Apply the Process**: Each $\\det(M_{ij})$ is a $4 \\times 4$ determinant, calculated as described before.\n",
    "\n",
    "As mentioned earlier the computational complexity of finding the determinant this way grows factorially with the size of the matrix. For large matrices, more efficient algorithms like LU decomposition, QR decomposition, or leveraging properties of special matrices (e.g., sparse matrices) are often used.\n",
    "\n",
    "### LU Decomposition\n",
    "\n",
    "LU decomposition decomposes a matrix into a lower triangular matrix (L) and an upper triangular matrix (U). You can then compute the determinant by taking the product of the diagonal elements of the U matrix.\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from scipy.linalg import lu\n",
    "\n",
    "# Create a large matrix\n",
    "A = np.array([[a, b, c, d],\n",
    "              [e, f, g, h],\n",
    "              [i, j, k, l],\n",
    "              [m, n, o, p]])\n",
    "\n",
    "# Perform LU decomposition\n",
    "P, L, U = lu(A)\n",
    "\n",
    "# Calculate the determinant as the product of the diagonals of U\n",
    "determinant = np.prod(np.diag(U))\n",
    "\n",
    "print(\"Determinant using LU decomposition:\", determinant)\n",
    "```\n",
    "\n",
    "### QR Decomposition\n",
    "\n",
    "QR decomposition decomposes a matrix into an orthogonal matrix (Q) and an upper triangular matrix (R). The determinant is the product of the diagonal elements of the R matrix, considering the sign of the permutation matrix.\n",
    "\n",
    "Here's how to do it in NumPy:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create a large matrix\n",
    "A = np.array([[a, b, c, d],\n",
    "              [e, f, g, h],\n",
    "              [i, j, k, l],\n",
    "              [m, n, o, p]])\n",
    "\n",
    "# Perform QR decomposition\n",
    "Q, R = np.linalg.qr(A)\n",
    "\n",
    "# Calculate the determinant as the product of the diagonals of R\n",
    "determinant = np.prod(np.diag(R)) * np.linalg.det(Q)\n",
    "\n",
    "print(\"Determinant using QR decomposition:\", determinant)\n",
    "```\n",
    "\n",
    "### Using `numpy.linalg.det`\n",
    "\n",
    "For direct computation, you can also use NumPy’s built-in determinant function, which is optimized for larger matrices:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "\n",
    "# Create a large matrix\n",
    "A = np.array([[a, b, c, d],\n",
    "              [e, f, g, h],\n",
    "              [i, j, k, l],\n",
    "              [m, n, o, p]])\n",
    "\n",
    "# Calculate the determinant directly\n",
    "determinant = np.linalg.det(A)\n",
    "\n",
    "print(\"Determinant using numpy.linalg.det:\", determinant)\n",
    "```\n",
    "\n",
    "These methods leverage optimized algorithms and are more efficient for larger matrices compared to manual cofactor expansion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Determinant using LU decomposition: 2592.0000000000023\n",
      "Determinant using QR decomposition: 2592.0000000000005\n",
      "Determinant using numpy.linalg.det: 2592.0000000000023\n"
     ]
    }
   ],
   "source": [
    "# Numerical example\n",
    "A = np.array([\n",
    "    [ 1,-2,  3,  4],\n",
    "    [ 5, 6,  7,  8],\n",
    "    [10,11,-12, 13],\n",
    "    [14,15, 16, 17]\n",
    "])\n",
    "\n",
    "from scipy.linalg import lu\n",
    "P,L,U = lu(A)\n",
    "determinant = np.prod(np.diag(U))\n",
    "print(\"Determinant using LU decomposition:\", determinant)\n",
    "\n",
    "Q, R = np.linalg.qr(A)\n",
    "determinant = np.prod(np.diag(R)) * np.linalg.det(Q)\n",
    "print(\"Determinant using QR decomposition:\", determinant)\n",
    "\n",
    "determinant = np.linalg.det(A)\n",
    "print(\"Determinant using numpy.linalg.det:\", determinant)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
