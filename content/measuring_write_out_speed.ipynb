{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measuring write speed.\n",
    "\n",
    "To little surprise I've observed that the OS blocks rapid successive access to the same file. \n",
    "\n",
    "What baffled me was the question of how much? \n",
    "\n",
    "In stead of thinking about random bits, I find it better to measure thing. Applied sciences please!\n",
    "\n",
    "So here we go: What I want to measure is:\n",
    "\n",
    "1. How much time to write 50Mb raw text to disk in 50 files (in parallel)\n",
    "2. How much time to write 50Mb raw text to disk in 50 files (serial)\n",
    "3. How much time to write 50Mb numpy ints to HDF5 into 1 file (in parallel)\n",
    "4. How much time to write 50Mb numpy ints to 50 HDF5 files (in parallel)\n",
    "\n",
    "\n",
    "\n",
    "Here's the code (It won't run in jupyter due to multiprocessing limitations that I still need to figure out):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import tempfile\n",
    "import time\n",
    "from mplite import Task, TaskManager\n",
    "\n",
    "\n",
    "dataset_size = int(1e6)\n",
    "\n",
    "\n",
    "def write(n):\n",
    "    while True:\n",
    "        try:\n",
    "            data = [f\"{i}\\n\" for i in range(dataset_size)]\n",
    "            with open(n,'w') as fo:\n",
    "                fo.write(\"\".join(data))\n",
    "            return\n",
    "        except MemoryError:\n",
    "            time.sleep(0.01)\n",
    "        except OSError:\n",
    "            time.sleep(0.01)\n",
    "        \n",
    "\n",
    "def h5write(n, group=1):\n",
    "    while True:\n",
    "        try:\n",
    "            with h5py.File(n,'a') as h5:\n",
    "                data = np.array([i for i in range(dataset_size)])\n",
    "                h5.create_dataset(name=f\"/{group}\", data=data, dtype=data.dtype, maxshape=(None, ))\n",
    "            return\n",
    "        except MemoryError:\n",
    "            time.sleep(0.01)\n",
    "        except OSError:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "\n",
    "def parallel_write_test():      \n",
    "    folder = pathlib.Path(tempfile.gettempdir()) / 'tablite_os_test'\n",
    "    if not folder.exists():\n",
    "        folder.mkdir()\n",
    "    \n",
    "    # parallel different files    \n",
    "    start = time.perf_counter()\n",
    "    tasks = []\n",
    "    for fileno in range(0,50):\n",
    "        path = folder / f\"test_file{fileno}.txt\"\n",
    "        tasks.append(Task(write, str(path)))\n",
    "    \n",
    "    with TaskManager() as tm:\n",
    "        results = tm.execute(tasks)\n",
    "        assert all(i is None for i in results), [print(r) for r in results]\n",
    "    end = time.perf_counter()\n",
    "    print(f'parallel took: {end-start}')\n",
    "\n",
    "    # serial different files.\n",
    "    start2 = time.perf_counter()\n",
    "    for fileno in range(51,100):\n",
    "        path = folder / f\"test_file{fileno}.txt\"\n",
    "        write(str(path))\n",
    "    end2 = time.perf_counter()\n",
    "    print(f\"serial took {end2-start2} \")\n",
    "\n",
    "    # parallel same hdf file.    \n",
    "    start3 = time.perf_counter()\n",
    "    p = folder / \"test_file.h5\"\n",
    "    tasks = []\n",
    "    for group in range(100,150):\n",
    "        tasks.append( Task(h5write, str(p), group))\n",
    "    with TaskManager() as tm:\n",
    "        results = tm.execute(tasks)\n",
    "        assert all(i is None for i in results), [print(r) for r in results]\n",
    "    end3 = time.perf_counter()\n",
    "    print(f\"parallel same hdf file {end3-start3} \")\n",
    "\n",
    "    # parallel multiple hdf files.    \n",
    "    start4 = time.perf_counter()\n",
    "    \n",
    "    tasks = []\n",
    "    for fileno in range(150,200):\n",
    "        path = folder / f\"test_file{fileno}.h5\"\n",
    "        tasks.append( Task(h5write, str(path)))\n",
    "    with TaskManager() as tm:\n",
    "        results = tm.execute(tasks)\n",
    "        assert all(i is None for i in results), [print(r) for r in results]\n",
    "    end4 = time.perf_counter()\n",
    "    print(f\"parallel multiple hdf files {end4-start4} \")\n",
    "\n",
    "    # python os_test.py\n",
    "    # 100%|██████████████████████████████████████| 50/50 [00:02<002<00:00, 22.57tasks/s]\n",
    "    # parallel took: 2.6400329999996757\n",
    "    # serial took 8.967031500000303                                                                                                      0:00, 22.57tasks/s]\n",
    "    # 100%|██████████████████████████████████████| 50/50 [00:04<004<00:00, 10.36tasks/s]\n",
    "    # parallel same hdf file 5.3461384000002                                                                                             0:00, 10.36tasks/s]\n",
    "    # 100%|██████████████████████████████████████| 50/50 [00:01<001<00:00, 33.80tasks/s]                                                                                                            0:00, 33.80tasks/s]\n",
    "    # parallel multiple hdf files 2.0312580999998318\n",
    "\n",
    "    # conclusion: parallel write ....\n",
    "    # 1. to multiple HDF5 files is at least as fast as parallel write.\n",
    "    # 2. to same HDF% file requires delay of 2.6x\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parallel_write_test()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('pages310')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f432a2729e41e111fc68229d0303145971e0c11421dc22cdb03f95edd20be36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
