{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The lifecycle of a shared_memory object in python.\n",
    "\n",
    "Also known as [bug 82300](https://github.com/python/cpython/issues/82300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Using shared memory objects make no sense outside a multi processing context, so I'll take that for granted in the rest of this post. I'll use two names: MAIN and SUB where sub is any subprocess started by main.\n",
    "\n",
    "The problem (as I experience it) is that shared_memory objects (SMOs) are garbage collected before the handover has happened.\n",
    "\n",
    "Case 1: Example that **works** because ref count > 0.\n",
    "\n",
    "* MAIN creates SMO and shares the SMO-name with SUB.\n",
    "* SUB accesses SMO, does work and closes.\n",
    "\n",
    "Case 2: Example that **doesn't work** because ref count == 0 before MAIN connext.\n",
    "\n",
    "* MAIN creates task for SUB.\n",
    "* SUB creates SMO and shares SMO-name with MAIN through a queue.\n",
    "* MAIN is busy and doesn't see SMO-name until SUB has left the name space where the last SMO reference existed.\n",
    "\n",
    "So it turns out that Python's Garbage Collector does its job very well. \n",
    "\n",
    "I can solve the last example using the robust Notify-Acknowledge-Transfer (NAT) protocol. The NAT protocol solves case 2 as follows:\n",
    "\n",
    "|step| description|\n",
    "|---|---|\n",
    "|NOTIFY | SUB has ref count, and notifies MAIN of SMO creation name  |\n",
    "|ACK | MAIN creates ref count and acknowledges SMO existence to SUB |\n",
    "|TRANSFER COMPLETE | SUB destroys ref count and declares the transfer as \"complete\". |\n",
    "\n",
    "\n",
    "**High level implementation details:**\n",
    "\n",
    "MAIN has global dict SHMmain and SUB has global dict SHMsub which are used as hard references to avoid GC count to reach zero. The process is roughly as follows:\n",
    "\n",
    "1. SUB creates SMO\n",
    "2. SUB sets hard ref in SHMsub[SMO.name] = SMO\n",
    "3. SUB notifies MAIN about SMO.name\n",
    "4. SUB does value-adding work and enters sleeps mode as long as SHMsub is not empty (e.g. won't exit)\n",
    "5. (delay) \n",
    "6. MAIN reads notification from SUB, connects to SMO and creates entry in SHMmain[SMO.name] = SMO\n",
    "7. MAIN returns acceptance to SUB\n",
    "8. SUB either finishes work or awakens from sleep and reads the acceptance message from MAIN. \n",
    "9. SUB can now remove the hard reference as `del SHMsub[SMO.name]` and let gc do it's work.\n",
    "10. after deletion of the reference SUB sends \"transfer complete\" message to MAIN which signals that MAIN is now allowed to remove the hard reference as well.\n",
    "\n",
    "**What if...:**\n",
    "\n",
    "* If SUB crashes after NOTIFICATION, MAIN will raise OS error for SMO name not found. No big issue.\n",
    "* If MAIN is busy for a very long time, NOTIFICATION will not be read. This could eventually lead to OutOfMemory error. Not a problem either.\n",
    "* SUB is not blocked by MAIN, as SUB can still collect other tasks from its task queue and keep processing. The receipt of ACKNOWLEDGE merely becomes a task to clear out the SMO.name from SHMsub.\n",
    "\n",
    "**Implementation**\n",
    "\n",
    "There are 5 classes\n",
    "\n",
    "| class | description |\n",
    "|---|---|\n",
    "|TaskManager | Used like multiprocessing.Pool, except I need it to do more.| \n",
    "|Worker | wrapper for the subprocess |\n",
    "|NATsignal| envelope for sharing `shm.name` between MAIN and SUB |\n",
    "|TrackedSharedMemory | wrapper for shared_memory.SharedMemory so that I can ref count in both processes |\n",
    "|Task| An envelope for the workers job `Task( f , *args, **kwargs)` |\n",
    "\n",
    "The implementation is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import shared_memory, cpu_count\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import queue\n",
    "from abc import ABC\n",
    "import copy\n",
    "from itertools import count\n",
    "import io\n",
    "import numpy as np\n",
    "import traceback\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class TaskManager(object):\n",
    "    shared_memory_references = {}  \n",
    "    shared_memory_reference_counter = defaultdict(int)  # tracker for the NAT protocol.\n",
    "\n",
    "    def __init__(self) -> None:    \n",
    "        self._cpus = cpu_count()\n",
    "        self.tq = multiprocessing.Queue()  # task queue for workers.\n",
    "        self.rq = multiprocessing.Queue()  # result queue for workers.\n",
    "        self.pool = []                     # list of sub processes\n",
    "        self.pool_sigq = {}                # signal queue for each worker.\n",
    "        self.tasks = 0                     # counter for task tracking\n",
    "        \n",
    "    def __enter__(self):\n",
    "        self.start()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, exc_type, exc_val, exc_tb): # signature requires these, though I don't use them.\n",
    "        self.stop()  # stop the workers.\n",
    "        \n",
    "        # Clean up on exit.\n",
    "        for k,v in self.shared_memory_reference_counter.items():\n",
    "            if k in self.shared_memory_references and v == 0:\n",
    "                del self.shared_memory_references[k]  # this unlinks the shared memory object,\n",
    "                # which now can be GC'ed if no other variable points to it.\n",
    "        \n",
    "    def start(self):\n",
    "        for i in range(self._cpus):  # create workers\n",
    "            name = str(i)\n",
    "            sigq = multiprocessing.Queue()  # we create one signal queue for each proc.\n",
    "            self.pool_sigq[name] = sigq\n",
    "            worker = Worker(name=name, tq=self.tq, rq=self.rq, sigq=sigq)\n",
    "            self.pool.append(worker)\n",
    "\n",
    "        with tqdm(total=self._cpus, unit=\"n\", desc=\"workers ready\") as pbar:\n",
    "            for p in self.pool:\n",
    "                p.start()\n",
    "\n",
    "            while True:\n",
    "                alive = sum(1 if p.is_alive() else 0 for p in self.pool)\n",
    "                pbar.n = alive\n",
    "                pbar.refresh()\n",
    "                if alive < self._cpus:\n",
    "                    time.sleep(0.01)\n",
    "                else:\n",
    "                    break  # all sub processes are alive. exit the setup loop.\n",
    "\n",
    "    def execute(self, tasks):\n",
    "        if isinstance(tasks, Task):\n",
    "            task = (tasks,)\n",
    "        if not isinstance(tasks, (list,tuple)) or not all([isinstance(i, Task) for i in tasks]):\n",
    "            raise TypeError\n",
    "\n",
    "        for t in tasks:\n",
    "            self.tq.put(t)\n",
    "            self.tasks += 1  # increment task counter.\n",
    "        \n",
    "        results = []  \n",
    "        with tqdm(total=self.tasks, unit='task') as pbar:\n",
    "            while self.tasks != 0:\n",
    "                try:\n",
    "                    task = self.rq.get_nowait()\n",
    "                \n",
    "                    if isinstance(task, NATsignal): \n",
    "                        if task.shm_name not in self.shared_memory_references:  # its a NOTIFY from a WORKER.\n",
    "                            # first create a hard ref to the memory object.\n",
    "                            self.shared_memory_references[task.shm_name] = TrackedSharedMemory(name=task.shm_name, create=False)\n",
    "                            self.shared_memory_reference_counter[task.shm_name] += 1\n",
    "                            # then send the ACKNOWLEDGEMENT directly to the WORKER.\n",
    "                            self.pool_sigq[task.worker_name].put(task)\n",
    "                        else:  # It's the second time we see the name so it's a TRANSFER COMPLETE\n",
    "                            self.shared_memory_reference_counter[task.shm_name] -= 1 \n",
    "                        # at this point we can be certain that the SHMs are in the main process.\n",
    "                        continue  # keep looping as there may be more.\n",
    "\n",
    "                    elif isinstance(task, Task):\n",
    "                        if task.exception:\n",
    "                            raise Exception(task.exception)\n",
    "\n",
    "                        self.tasks -= 1  # decrement task counter.\n",
    "                        pbar.set_description(task.f.__name__)\n",
    "                        results.append(task)\n",
    "                        pbar.update(1)\n",
    "                    \n",
    "                except queue.Empty:\n",
    "                    time.sleep(0.01)\n",
    "        return results \n",
    "\n",
    "    def stop(self):\n",
    "        for _ in range(self._cpus):  # put enough stop messages for all workers.\n",
    "            self.tq.put(\"stop\")\n",
    "\n",
    "        with tqdm(total=len(self.pool), unit=\"n\", desc=\"workers stopping\") as pbar:\n",
    "            while True:\n",
    "                not_alive = sum(1 if not p.is_alive() else 0 for p in self.pool)\n",
    "                pbar.n = not_alive\n",
    "                pbar.refresh()\n",
    "                if not_alive < self._cpus:\n",
    "                    time.sleep(0.01)\n",
    "                else:\n",
    "                    break\n",
    "        self.pool.clear()\n",
    "\n",
    "        # clear the message queues.\n",
    "        while not self.tq.empty:  \n",
    "            _ = self.tq.get_nowait()  \n",
    "        while not self.rq.empty:\n",
    "            _ = self.rq.get_nowait()\n",
    "        \n",
    "  \n",
    "class Worker(multiprocessing.Process):\n",
    "    def __init__(self, name, tq, rq, sigq):\n",
    "        super().__init__(group=None, target=self.update, name=name, daemon=False)\n",
    "        self.exit = multiprocessing.Event()\n",
    "        self.tq = tq  # workers task queue\n",
    "        self.rq = rq  # workers result queue\n",
    "        self.sigq = sigq  # worker signal reciept queue.\n",
    "        \n",
    "               \n",
    "    def update(self):\n",
    "        # this is global for the sub process only.\n",
    "        TaskManager.shared_memory_references  \n",
    "\n",
    "        while True:\n",
    "            # first process any/all direct signals first.\n",
    "            while True:\n",
    "                try:\n",
    "                    ack = self.sigq.get_nowait()   # receive acknowledgement of hard ref to SharedMemoryObject from SIGQ            \n",
    "                    shm = TaskManager.shared_memory_references.pop(ack.shm_name)  # pop the shm\n",
    "                    shm.close()  # assure closure of the shm.\n",
    "                    del TaskManager.shared_memory_reference_counter[ack.shm_name]\n",
    "                    self.rq.put(ack)  # respond to MAINs RQ that transfer is complete.\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "\n",
    "            # then deal with any tasks...\n",
    "            try:  \n",
    "                task = self.tq.get_nowait()\n",
    "                if task == \"stop\":\n",
    "                    self.tq.put_nowait(task)  # this assures that everyone gets the stop signal.\n",
    "                    self.exit.set()\n",
    "                    break\n",
    "                elif isinstance(task, Task):\n",
    "                    task.execute()\n",
    "                    \n",
    "                    for k,v in TaskManager.shared_memory_references.items():\n",
    "                        if k not in TaskManager.shared_memory_reference_counter:\n",
    "                            TaskManager.shared_memory_reference_counter[k] = 1\n",
    "                            self.rq.put(NATsignal(k, self.name))  # send Notify from subprocess to main\n",
    "                        \n",
    "                    self.rq.put(task)\n",
    "\n",
    "                else:\n",
    "                    raise Exception(f\"What is {task}?\")\n",
    "            except queue.Empty:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "\n",
    "\n",
    "class NATsignal(object):\n",
    "    def __init__(self, shm_name, worker_name):\n",
    "        \"\"\"\n",
    "        shm_name: str: name from shared_memory.\n",
    "        worker_name: str: required by TaskManager for sending ACK message to worker.\n",
    "        \"\"\"\n",
    "        self.shm_name = shm_name\n",
    "        self.worker_name = worker_name\n",
    "\n",
    "\n",
    "class TrackedSharedMemory(shared_memory.SharedMemory):\n",
    "    def __init__(self, name=None, create=False, size=0) -> None:\n",
    "        if name in TaskManager.shared_memory_references:\n",
    "            return TaskManager.shared_memory_references[name]  # return from registry.\n",
    "        else:\n",
    "            super().__init__(name, create, size)\n",
    "            TaskManager.shared_memory_references[self.name] = self  # add to registry. This blocks __del__ !  \n",
    "\n",
    "\n",
    "class Task(ABC):\n",
    "    \"\"\"\n",
    "    Generic Task class for tasks.\n",
    "    \"\"\"\n",
    "    ids = count(start=1)\n",
    "    def __init__(self, f, *args, **kwargs) -> None:\n",
    "        \"\"\"\n",
    "        f: callable \n",
    "        *args: arguments for f\n",
    "        **kwargs: keyword arguments for f.\n",
    "        \"\"\"\n",
    "        if not callable(f):\n",
    "            raise TypeError\n",
    "        self.task_id = next(self.ids)\n",
    "        self.f = f\n",
    "        self.args = copy.deepcopy(args)  # deep copy is slow unless the data is shallow.\n",
    "        self.kwargs = copy.deepcopy(kwargs)\n",
    "        self.result = None\n",
    "        self.exception = None\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        if self.exception:\n",
    "            return f\"Call to {self.f.__name__}(*{self.args}, **{self.kwargs}) --> Error: {self.exception}\"\n",
    "        else:\n",
    "            return f\"Call to {self.f.__name__}(*{self.args}, **{self.kwargs}) --> Result: {self.result}\"\n",
    "\n",
    "    def execute(self):\n",
    "        \"\"\" The worker calls this function. \"\"\"\n",
    "        try:\n",
    "            self.result = self.f(*self.args, **self.kwargs)\n",
    "        except Exception as e:\n",
    "            f = io.StringIO()\n",
    "            traceback.print_exc(limit=3, file=f)\n",
    "            f.seek(0)\n",
    "            error = f.read()\n",
    "            f.close()\n",
    "            self.exception = error\n",
    "\n",
    "\n",
    "def cpu_intense_task_with_shared_memory(n):\n",
    "    # create shared memory object\n",
    "    arr = np.array(list(range(n)))\n",
    "    shm = TrackedSharedMemory(create=True, size=arr.nbytes)\n",
    "    datablock = np.ndarray(arr.shape, dtype=arr.dtype, buffer=shm.buf)\n",
    "    datablock[:] = arr[:]  # copy the data.\n",
    "    # disconnect from the task.\n",
    "    return shm.name, datablock.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \"\"\" test... \"\"\"\n",
    "    n = 9\n",
    "\n",
    "    tasks =[ Task(f=cpu_intense_task_with_shared_memory, n=10**i) for i in range(n) ]\n",
    "    \n",
    "    with TaskManager() as tm:  # start sub procs by using the context manager.\n",
    "        results = tm.execute(tasks)\n",
    "        results.sort(key=lambda x: x.task_id)\n",
    "\n",
    "        # collect evidence that it worked.\n",
    "        assert len(results) == len(tasks)\n",
    "\n",
    "        result_names, arrays = set(), []\n",
    "        total = 0 \n",
    "        for r in results:\n",
    "            result_name, shape = r.result\n",
    "            result_names.add(result_name)\n",
    "            shm = tm.shared_memory_references[result_name]\n",
    "            data = np.ndarray(shape, dtype=int, buffer=shm.buf)\n",
    "            total += data.shape[0]  # get the data from the workers.\n",
    "            \n",
    "            arrays.append(data)\n",
    "\n",
    "        tm_names = set(tm.shared_memory_references.keys())\n",
    "        assert result_names == tm_names, (result_names, tm_names)\n",
    "        assert total == sum(10**i for i in range(n)), total\n",
    "    # stop all subprocs by exiting the context mgr.\n",
    "\n",
    "    # check the data is still around.\n",
    "    assert sum(len(arr) for arr in arrays) == total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## output:\n",
    "\n",
    "```\n",
    "(py39tablite) C:\\Data\\github\\tablite>c:/Data/venv/py39tablite/Scripts/python.exe c:/Data/github/tablite/tests/a_multi_proc_shm_test.py\n",
    "workers ready: 100%|██████████████████████████████████████████████████| 8/8 [00:00<00:00, 91.95n/s] \n",
    "cpu_intense_task_with_shared_memory: 100%|█████████████████████████| 9/9 [00:12<00:00,  1.34s/task] \n",
    "workers stopping: 100%|███████████████████████████████████████████████| 8/8 [00:00<00:00, 31.73n/s]\n",
    "\n",
    "(py39tablite) C:\\Data\\github\\tablite>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the code is comprehensively annotated, I can only say that it requires a clear mind to solve the problem.\n",
    "\n",
    "First it must be recognised that MAIN and SUB have the same classes available. That's why the TaskManagers `shared_memory_references` can be used by both SUB and MAIN.\n",
    "\n",
    "Second it must be recognised that MAIN and SUB do not have the same in memory content, which is why it works: MAIN has the TaskManager running as tracker of all shared_memory objects, whilst SUB uses the TaskManager for its \"locally known\" shared_memory objects.\n",
    "\n",
    "Third, the usage of subclassing `shared_memory.SharedMemory` as `TrackedSharedMemory` gives a single API for objects, whereby testing and actual usage have no difference.\n",
    "\n",
    "Fourth, the implementation is done so the user NEVER sees these details: TaskManager works with GC directly using the context management methods `__enter__` and `__exit__`.\n",
    "\n",
    "...\n",
    "\n",
    "Afterthought: It would be great if this was implemented in python, but I understand why it isn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
