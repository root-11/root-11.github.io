{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Problems with text as tables (draft)\n",
    "\n",
    "## State of research on CSV files\n",
    "\n",
    "CSV used to stand for \"***comma*** separated values\", however recent research done by [Mitlöhner et.al](ref/mitl-etal-2016OBD.pdf),\n",
    "concludes that it is more appropriate to to refer to CSV as \"***character*** separated values\", which echoes\n",
    "concerns expressed by [Shafranovich, Y., 2005.](https://www.hjp.at/doc/rfc/rfc4180.html#sec_1) in the RFC4180:\n",
    "\"Common format and MIME type for comma-separated values (CSV) files.\"\n",
    "\n",
    "In research prior to 2016 reading CSV files has been treated as a parsing problem.\n",
    "2016 changed the approach, where it is being treated as a pattern recognition problem.\n",
    "\n",
    "Between 2016 and 2018 the W3C consortium ran a work group who recommended CSV files\n",
    "to be accompanied by a JSON which declares the dialect required to interpret the CSV\n",
    "and required the CSV and JSON to be encoded in UTF-8.\n",
    "\n",
    "A few implementations exist, such as [Frictionless (Java)](https://github.com/frictionlessdata/specs/tree/master/csv-dialect),\n",
    "XXX a number of university projects xXXX, but no PyPi packages exist to read the dialects json.\n",
    "Should the dialect file exist, the user will be required to interpret it and translate it into, python\n",
    "`kwargs`.\n",
    "\n",
    "Furthermore, the requirement to use UTF-8 has not been adopted in the wild. The consequence hereof is\n",
    "several conversations in various forums why CSV readers can't read the data, where the reality is that\n",
    "interpretation of CSV files requires additional knowledge about the encoding as this \"standard W3C\n",
    "recommendation\" can't be taken for granted.\n",
    "\n",
    "Finally, scraping of code on github reveals that CSV files frequently are compressed immediately after\n",
    "creation. Following the thinking mental model that Python libraries exist for relieving the developer\n",
    "of trivial matters, this practice should probably be considered. The W3C CSV work group recommends this\n",
    "practice as it makes the CSV file and dialect accompany one another.\n",
    "\n",
    "Last, but not least, most CSV writers do not produce the two files on output, nor permit the output to\n",
    "be compressed.\n",
    "\n",
    "## API\n",
    "\n",
    "The requirements for pandas, would be:\n",
    "\n",
    "[1] To ***read*** W3C defined CSV given pathlib.Path(s).\n",
    "\n",
    "- If a single Path is given and the path.endswith `.zip`, the archive is decompressed with expectations to\n",
    "find a single data and dialect file.\n",
    "\n",
    "- If two paths are given, ending with `.csv` and `.json`, the csv can be read using the dialect file.\n",
    "\n",
    "\n",
    "[2] To ***write*** W3C defined CSV given a pandas table and pathlib.Path(s).\n",
    "\n",
    "- If a single path.name is given and ends with:\n",
    "\n",
    "  -`zip` a compressed file is made with both data and dialect.\n",
    "\n",
    "  -`csv` a file is made with data.\n",
    "\n",
    "  -`json` a file is made with the dialect.\n",
    "\n",
    "- If two paths are given and each end with `.csv` and `.json` two files are created with respectively\n",
    "the data and the dialect.\n",
    "\n",
    "[3] To read pathlib.Path or IoStream without dialect file and automatically detect the dialect.\n",
    "\n",
    "  - This permits pandas to create a dialect file and use it for interpreting the data.\n",
    "  - It is important to recognise the separation of concerns between the dialect detection\n",
    "    and reading the data.\n",
    "  - The detection will apply the practices developed by [Gerrit J.J. van den Burg, et.al](https://arxiv.org/pdf/1811.11242.pdf)\n",
    "described further below.\n",
    "\n",
    "\n",
    "### Estimating encoding and dialect\n",
    "\n",
    "\n",
    "Conversations in forums extend the CSV problem to include encoding as the W3C recommendation\n",
    "\n",
    "Existing csv-readers and file sniffers fail because they:\n",
    "- presume US-ASCII or don't detect correct UTF+ era encoding.\n",
    "- attempt to parser based on incorrect encoding.\n",
    "- continue parsing despite that the format isn't recognised as tabular / rectangular.\n",
    "  - Documents that hold more than one table which are separated by repeated line breaks.\n",
    "  - Attempt to maintain a number of columns despite that the required number of delimiters exceed the rectangular format.\n",
    "- Presume no or one line in the header, despite that multiline headers are detected in the wild.\n",
    "- skip the last line because it is missing a newline character (optional in RFC4180)\n",
    "- don't handle text escapes during column detection (RFC4180 expectation).\n",
    "- presume that text escapes are based on double qoutes `\"` and ignore commonly used brackets.\n",
    "- dump leading zeros when inferring integer values.\n",
    "- omitting empty columns and other [rules](https://cchristodoulaki.github.io/Pytheas/)\n",
    "- usage of field detection like `dateutils` where the parser only evaluates a single value and will\n",
    "  always say that 01.02.2012 is mm.dd.yyyy despite that the next value might be 29.2.2012 (I've got plenty of tests with that problem).\n",
    "\n",
    "> file = [header CRLF] record *(CRLF record) [CRLF]\n",
    "> header = name *(COMMA name)\n",
    "> record = field *(COMMA field)\n",
    "> name = field\n",
    "> field = (escaped / non-escaped)\n",
    "> escaped = DQUOTE *(TEXTDATA / COMMA / CR / LF / 2DQUOTE) DQUOTE\n",
    "> non-escaped = *TEXTDATA\n",
    "> COMMA = %x2C\n",
    "> CR = %x0D ;as per section 6.1 of RFC 2234 [2]\n",
    "> DQUOTE =  %x22 ;as per section 6.1 of RFC 2234 [2]\n",
    "> LF = %x0A ;as per section 6.1 of RFC 2234 [2]\n",
    "> CRLF = CR LF ;as per section 6.1 of RFC 2234 [2]\n",
    "> TEXTDATA =  %x20-21 / %x23-2B / %x2D-7E\n",
    "\n",
    "\n",
    "Here's an ugly `example-1`:\n",
    "\n",
    "`Birthdate, (Family\\nnames), Father, Mother, Child, known for\\n1879-4-14, Einstein, Hermann, Pauline, Albert,\"\\nGeneral relativity,\\nSpecial relativity,\\nPhotoelectric effect\"`\n",
    "\n",
    "That should produce `table-1` (including some text escape):\n",
    "\n",
    "|Birthdate| (Family<br>names)| Father | Mother | Child | known for |\n",
    "|---|---|---|---|---|---|\n",
    "|1879-4-14| Einstein| Hermann| Pauline| Albert| General relativity,<br>Special relativity,<br>Photoelectric effect|\n",
    "\n",
    "\n",
    "Data sources:\n",
    "\n",
    "- https://open.canada.ca/en\n",
    "- the turing institute\n",
    "- [csv_files from Mitlöhner et.al](refs/csv_files.csv) and [https://archiver.ai.wu.ac.at/](https://archiver.ai.wu.ac.at/)\n",
    "- proprietary and confidential data (undisclosed, 1.5Tb)\n",
    "\n",
    "Perspectives:\n",
    "- https://github.com/cchristodoulaki/Pytheas\n",
    "- https://www.gov.uk/government/publications/recommended-open-standards-for-government/using-metadata-to-describe-csv-data\n",
    "- https://data.wu.ac.at/csvengine/\n",
    "- https://github.com/w3c/csvw\n",
    "\n",
    "\n",
    "### The ground truth.\n",
    "\n",
    "To determine the ground truth, we do the following:\n",
    "\n",
    "1. Assert the ability to generate csv from config and reconstruct config from csv.\n",
    "2. Assert the ability to read CSVs \"from the wild\" and provide a clear declaration of errors.\n",
    "3. Generate CSV files using various implementations, python, etc. and reconstruct the dialect.\n",
    "\n",
    "\n",
    "arxiv.x uses a \"score\" to determine best match. I prefer that score to be entropy:\n",
    "\n",
    "```python\n",
    "def entropy(value_counts):\n",
    "    \"\"\" Input is a db of value counts e.g. {True: 10, False:100, NULL: 5} \"\"\"\n",
    "    # Compute the shannon entropy of a column\n",
    "    size = sum(value_counts.values())\n",
    "    h_entropy = 0.0\n",
    "    for _, count in value_counts.items():\n",
    "        proportion = (count/size)\n",
    "        h_entropy -= proportion * math.log(proportion, 2)\n",
    "    return h_entropy\n",
    "```\n",
    "\n",
    "\n",
    "### real world dirt - [source](https://arxiv.org/pdf/1811.11242.pdf)\n",
    "```\n",
    "functions,,:stop,\"a[u:stop,i]\"\n",
    "functions,,:stop,a[u:stop:b]\n",
    "hotshot,,:lineno,\"ncalls tottime\"\n",
    "httplib,,:port,host:port\n",
    "imaplib,,:MM,\"DD-MM-YY\"\n",
    "```\n",
    "\n",
    "```\n",
    "~437~^~a~^~Approve~^~3~^~13482~\n",
    "~688~^~b~^~Jellyfish~^~1~^~12880~\n",
    "~498~^~c~^~Color~^~2~^~13629~\n",
    "~992~^~a~^~Wind~^~8~^~12392~\n",
    "~246~^~c~^~Coat~^~0~^~13764~\n",
    "```\n",
    "\n",
    "```\n",
    "\"www.google.com,search,02/02/15\"\n",
    "\"www.yahoo.com,search,02/02/15\"\n",
    "\"www.bing.com,search,03/02/15\"\n",
    "\"altavista.com,search,03/02/15\"\n",
    "\"askjeeves.com,search,03/06/15\"\n",
    "```\n",
    "\n",
    "```\n",
    "#Release 0.4\n",
    "#Copyright (c) 2015 SomeCompany.\n",
    "#\n",
    "Z10,,,HFJ,,,,,,\n",
    "B12,,IZOY,AB_K9Z_DD_18,RED,,12,,,\n",
    "```\n",
    "\n",
    "```\n",
    "Mango; £365,14; £1692,64\n",
    "Apple; £2568,62; £1183,78\n",
    "Lemon; £51,65; £685,67\n",
    "Orange; £1760,75; £128,14\n",
    "Maple; £880,86; £323,43\n",
    "```\n",
    "\n",
    "\n",
    "```\n",
    "this, is, a file,\"\n",
    "with a number of issues\n",
    "that shows \"\"double quoting\"\"\n",
    "\\\"escaping\\\" and multi-line cells\n",
    "\",\\, and has only one row!\n",
    "```\n",
    "\n",
    "### Keys & properties.\n",
    "\n",
    "The CSV readers that I've encountered are mainly parsers that hope to apply a pattern which then is produces\n",
    "a valid table with data. The inputs for the `csv-[reader/parser/...]` are:\n",
    "\n",
    "| keyword | pandas |\n",
    "|---|---|\n",
    "|filepath_or_buffer|filepath_or_buffer|\n",
    "|sep|sep|\n",
    "|delimiter|delimiter|\n",
    "|header|header|\n",
    "|names|names|\n",
    "|index_col|index_col|\n",
    "|usecols|usecols|\n",
    "|squeeze|squeeze|\n",
    "|prefix|prefix|\n",
    "|mangle_dupe_cols|mangle_dupe_cols|\n",
    "|dtype|dtype|\n",
    "|engine|engine|\n",
    "|converters|converters|\n",
    "|true_values|true_values|\n",
    "|false_values|false_values|\n",
    "|skipinitialspace|skipinitialspace|\n",
    "|skiprows|skiprows|\n",
    "|skipfooter|skipfooter|\n",
    "|nrows|nrows|\n",
    "|na_values|na_values|\n",
    "|keep_default_na|keep_default_na|\n",
    "|na_filter|na_filter|\n",
    "|verbose|verbose|\n",
    "|skip_blank_lines|skip_blank_lines|\n",
    "|parse_dates|parse_dates|\n",
    "|infer_datetime_format|infer_datetime_format|\n",
    "|keep_date_col|keep_date_col|\n",
    "|date_parser|date_parser|\n",
    "|dayfirst|dayfirst|\n",
    "|cache_dates|cache_dates|\n",
    "|iterator|iterator|\n",
    "|chunksize|chunksize|\n",
    "|compression|compression|\n",
    "|thousands|thousands|\n",
    "|decimal|decimal|\n",
    "|lineterminator|lineterminator|\n",
    "|quotechar|quotechar|\n",
    "|quoting|quoting|\n",
    "|doublequote|doublequote|\n",
    "|escapechar|escapechar|\n",
    "|comment|comment|\n",
    "|encoding|encoding|\n",
    "|encoding_errors|encoding_errors|\n",
    "|dialect|dialect|\n",
    "|error_bad_lines|error_bad_lines|\n",
    "|warn_bad_lines|warn_bad_lines|\n",
    "|on_bad_lines|on_bad_lines|\n",
    "|delim_whitespace|delim_whitespace|\n",
    "|low_memory|low_memory|\n",
    "|memory_map|memory_map|\n",
    "|float_precision|float_precision|\n",
    "|storage_options|storage_options|\n",
    "\n",
    "When given great attention to details, it becomes obvious that the inputs to `pandas` will not\n",
    "suffice to convert `example-1` into `table-1`\n",
    "\n",
    "The goal of this project is to analyze any csv file and return a set of `**kwargs` required to read the csv file.\n",
    "\n",
    "\n",
    "### A solution?\n",
    "\n",
    "To enable the user to do the following:\n",
    "\n",
    "```\n",
    "import pandas as pd\n",
    "import csv_analyze\n",
    "from pathlib import Path\n",
    "\n",
    "df = pandas.csv_reader(somepath, **analyze(Path(s3://a_file.csv)))\n",
    "```\n",
    "\n",
    "This requires that:\n",
    "\n",
    "- The encoding using one of the ~300 python accepted [encodings](https://github.com/Ousret/charset_normalizer/blob/51af624b59a7f1a1aaa36f9ae71bee4364e39409/charset_normalizer/constant.py#L310)\n",
    "- analyse the file,\n",
    "- return the correct formats to pandas as **kwargs\n",
    "\n",
    "The output will contain all the required information to consume the csv file, including\n",
    "more detailed information from the analysis:\n",
    "\n",
    "```\n",
    "d = csv.analyze(path)\n",
    "d\n",
    "    {\"encoding\": {\"depth\": 10043,  # characters checked.\n",
    "                  'cp855': 10043,  # meaning 10043/10043 = 100% characters match.\n",
    "                  'utf_8_sig': 12,  # meaning decode error after 12th character.\n",
    "                  'utf-8': 5,\n",
    "                  \".....\"},\n",
    "     \"text_escape\": [False, True, False, False, True],\n",
    "     \"column_names\": [\"Birthdate\", \"(Family\\nnames)\", \"Father\", \"Mother \", \"Child\", \"known for\"],\n",
    "     \"datatypes\": [\"date\", \"str\", \"str\", \"str\", \"str\"],\n",
    "     \"metadata\": [  # in order like columns, with list of probabilities for each type.\n",
    "         {\"date\": {'yyyy-mm-dd': (100, 100),\n",
    "                   'mm-dd-yyyy': (0, 100),\n",
    "                   \"....\": (0, 0)},\n",
    "          \"time\": 0,\n",
    "          \"datetime\": 0,\n",
    "          \"str\": \"pass\",\n",
    "          \"int\": 0,\n",
    "          \"float\": 0},\n",
    "         {\"date\": ValueError, \"time\": ValueError, \"datetime\": ValueError, \"str\": (100, 100), \"int\": ValueError,\n",
    "          \"float\": ValueError},\n",
    "         {\"date\": ValueError, \"time\": ValueError, \"datetime\": ValueError, \"str\": (100, 100), \"int\": ValueError,\n",
    "          \"float\": ValueError},\n",
    "         {\"date\": ValueError, \"time\": ValueError, \"datetime\": ValueError, \"str\": (100, 100), \"int\": ValueError,\n",
    "          \"float\": ValueError},\n",
    "         {\"date\": ValueError, \"time\": ValueError, \"datetime\": ValueError, \"str\": (100, 100), \"int\": ValueError,\n",
    "          \"float\": ValueError}\n",
    "     ]\n",
    "     }\n",
    "```\n",
    "\n",
    "## What is required to recognize patterns in a csv file?\n",
    "\n",
    "5 properties must be established to recognize the pattern of a csv file:\n",
    "\n",
    "- Encoding.\n",
    "- Header / Footer information\n",
    "- Rectangular format which may not be carriage return / line break character\n",
    "- Field separation\n",
    "- Field interpretation:\n",
    "    - text escape\n",
    "    - datatype which may be a local text, date or number system\n",
    "\n",
    "\n",
    "### Encoding\n",
    "\n",
    "### Header / footer information\n",
    "\n",
    "### Rectangular format\n",
    "\n",
    "### Field separation\n",
    "\n",
    "### Field interpretation\n",
    "\n",
    "\n",
    "The strings I've encountered in csv data are:\n",
    "\n",
    "SEPARATORS\n",
    "\n",
    "```\n",
    "#,###.#####  last non-digit character indicates decimal, preceding different characters are thousand separators.\n",
    "#.###,#####\n",
    "```\n",
    "\n",
    "Examples:\n",
    "```\n",
    "4 294 967 295,000  Canadian (English and French), Danish, Finnish, French, German\n",
    "4.294.967.295,000  Italian, Norwegian, Spanish,\n",
    "4 294 967 295,000  Swedish\n",
    "4,294,967,295.000  GB-English, US-English, Thai\n",
    "```\n",
    "(full treaty on: https://en.wikipedia.org/wiki/Decimal_separator)\n",
    "\n",
    "However, notice that Hindi uses a 2-digit grouping, except for the 3-digit grouping for denoting hundreds: 12,34,56,789.00\n",
    "\n",
    "SCIENTIFIC NOTATION\n",
    "\n",
    "```\n",
    "   ###E###   integer before and after E\n",
    "   ###e###\n",
    "#.####E###   floating point before, integer after E\n",
    "#.####e###\n",
    "```\n",
    "\n",
    "```\n",
    "###.###N <=3 digit float, followed by N belongs to (K,M,G/B, T,E,P) for kilo, mega, giga/bill, tera, exa,...\n",
    "```\n",
    "\n",
    "POSITIVE/NEGATIVE\n",
    "\n",
    "Negative numbers can have tailing minus\n",
    "```\n",
    "527-\n",
    "-527\n",
    "(527)\n",
    "[527]\n",
    "```\n",
    "\n",
    "ADDITIONAL SIGNS\n",
    "\n",
    "The same applies for percentages: 98%, 98 %, 98 pct, %98\n",
    "And for currencies: $100.00, kr100,00\n",
    "\n",
    "NON-LATIN numbers\n",
    "\n",
    "NUMBER FORMATTING\n",
    "\n",
    "    Script\tDigits Used\n",
    "    Latin\t0 1 2 3 4 5 6 7 8 9\n",
    "    Arabic\t٠‎ ١‎ ٢‎ ٣‎ ٤‎ ٥‎ ٦‎ ٧‎ ٨‎ ٩\n",
    "    Chinese / Japanese\t〇 一 二 三 四 五 六 七 八 九 十…\n",
    "    Hebrew\tא ,ב ,ג, ד, ה, ו, ז, ח ,ט…\n",
    "    Korean\t일 이 삼 사 오 육 칠 팔 구…\n",
    "    The Korean regularly uses both a Sino-Korean system and a native Korean system. Everything that can be counted will use one of the two systems, but seldom both.\t하나 둘 셋 넷 다섯 여섯 일곱 여덟 아홉….\n",
    "    Bengla\t০ ১ ২ ৩ ৪ ৫ ৬ ৭ ৮ ৯\n",
    "    Devanagari (script used to write Hindi,Marathi, and other languages)\t० १ २ ३ ४ ५ ६ ७ ८ ९\n",
    "    Gujarati\t૦ ૧ ૨ ૩ ૪ ૫ ૬ ૭ ૮ ૯\n",
    "    Gurmukhi (one of the scripts used to write Punjabi)\t੦ ੧ ੨ ੩ ੪ ੫ ੬ ੭ ੮ ੯\n",
    "    Kannada\t೦ ೧ ೨ ೩ ೪ ೫ ೬ ೭ ೮ ೯\n",
    "    Malayalam\t൦ ൧ ൨ ൩ ൪ ൫ ൬ ൭ ൮ ൯\n",
    "    Odia\t୦ ୧ ୨ ୩ ୪ ୫ ୬ ୭ ୮ ୯\n",
    "    Tamil\t௦ ௧ ௨ ௩ ௪ ௫ ௬ ௭ ௮ ௯\n",
    "    Telugu\t౦ ౧ ౨ ౩ ౪ ౫ ౬ ౭ ౮ ౯\n",
    "    Thai\t๐ ๑ ๒ ๓ ๔ ๕ ๖ ๗ ๘ ๙\n",
    "    Tibetan\t༠ ༡ ༢ ༣ ༤ ༥ ༦ ༧ ༨ ༩\n",
    "\n",
    "FLOATING POINT\n",
    "the floating point precision issue (which in particular haunts anyone who reads long barcodes that aren't imported as integers):\n",
    "```\n",
    "val = \"0.3066101993807095471566981359501369297504425048828125\"\n",
    "print(float(val))\n",
    "0.30661019938070955\n",
    "```\n",
    "\n",
    "NOT A NUMBER\n",
    "```\n",
    "\"\", \"#N/A\", \"#N/A N/A\", \"#NA\", \"-1.#IND\", \"-1.#QNAN\", \"-NaN\", \"-nan\", \"1.#IND\", \"1.#QNAN\", \"<NA>\", \"N/A\", \"NA\", \"NULL\", \"NaN\", \"n/a\", \"nan\", \"null\". \"-\", \"--\", \"###\"\n",
    "```\n",
    "\n",
    "Similar variation appears in datetime locale:\n",
    "\n",
    "```\n",
    "yyyy-mm-dd  Canadian (English and French), Danish, German, Swedish\n",
    "dd.mm.yyyy  Finnish\n",
    "dd.mm.yy    Italian, Norwegian\n",
    "dd-mm-yy    Spanish\n",
    "dd/mm/yy    GB-English\n",
    "mm-dd-yy    US-English\n",
    "dd/mm/yyyy  Thai\n",
    "```\n",
    "\n",
    "And so for time:\n",
    "```\n",
    "23:59      Canadian\n",
    "23.59      Finnish\n",
    "23.59 Uhr  German\n",
    "Kl 23.59   Norwegian\n",
    "11:59 PM   Thai\n",
    "11.59 PM   UK english\n",
    "```\n",
    "\n",
    "TEXT ESCAPE\n",
    "Finally we also see newline characters in headers which the csv-reader cannot deal with. To detect the correct format of the example below multiple lines have to be read and the internal between newline and separators. These will also have to be text and bracket escaped.\n",
    "\n",
    "`Birthdate, (Family\\nnames), Father, Mother, Child, known for\\n1879-4-14, Einstein, Hermann, Pauline, Albert,\"\\nGeneral relativity,\\nSpecial relativity,\\nPhotoelectric effect\"`\n",
    "\n",
    "See table in introduction as `ugly example`\n",
    "\n",
    "LINEBREAK\n",
    "very old files can have linebreaks \\r \\r\\n or \\n\n",
    "\n",
    "### Data sources:\n",
    "\n",
    "Here is a [list with 1400 text based tabular files](https://gist.github.com/root-11/0cb2b328b313a7d269e28d4083a6a726)\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}