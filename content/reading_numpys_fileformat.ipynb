{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading numpys fileformat\n",
    "\n",
    "In the numpy manual there's a nice description of the [.npy fileformat](https://numpy.org/devdocs/reference/generated/numpy.lib.format.html#npy-format), with a note under [capabilities](https://numpy.org/devdocs/reference/generated/numpy.lib.format.html#capabilities) that says:\n",
    "\n",
    "> Is straightforward to reverse engineer.<br>Datasets often live longer than the programs that created them.<br>A competent developer should be able to create a solution in their preferred programming language to read most .npy files that they have been given without much documentation.\n",
    "\n",
    "So let's look at a numpy file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b\"\\x93NUMPY\\x01\\x00v\\x00{'descr': '<i4', 'fortran_order': False, 'shape': (13,), }                                                           \\n\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\x05\\x00\\x00\\x00d\\x00\\x00\\x00\\xc8\\x00\\x00\\x00,\\x01\\x00\\x00\\x90\\x01\\x00\\x00\\xf4\\x01\\x00\\x00X\\x02\\x00\\x00\\xbc\\x02\\x00\\x00 \\x03\\x00\\x00\"\n",
      "[  1   2   3   4   5 100 200 300 400 500 600 700 800]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "filename = \"1.npy\"\n",
    "original_array = np.array([1,2,3,4,5] + list(range(100,900,100)))\n",
    "np.save(filename, original_array)\n",
    "\n",
    "with open(filename, 'rb') as f:\n",
    "    print(f.read())\n",
    "\n",
    "print(original_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [documentation](https://numpy.org/devdocs/reference/generated/numpy.lib.format.html#format-version-1-0) tells us that:\n",
    "\n",
    "> **Format Version 1.0**<br>\n",
    "> The first 6 bytes are a magic string: exactly \\x93NUMPY.<br>\n",
    "> The next 1 byte is an unsigned byte: the major version number of the file format, e.g. \\x01.<br>\n",
    "> The next 1 byte is an unsigned byte: the minor version number of the file format, e.g. \\x00. Note: the version of the file format is not tied to the version of the numpy package.<br>\n",
    "> The next 2 bytes form a little-endian unsigned short int: the length of the header data HEADER_LEN.<br>\n",
    "> The next HEADER_LEN bytes form the header data describing the arrayâ€™s format. It is an ASCII string which contains a Python literal expression of a dictionary. It is terminated by a newline > (\\n) and padded with spaces (\\x20) to make the total of len(magic string) + 2 + len(length) + HEADER_LEN be evenly divisible by 64 for alignment purposes.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def read_npy_v1(filename):\n",
    "    with open(filename, \"rb\") as f:\n",
    "        arr = f.read(10)\n",
    "        magic = arr[:6]\n",
    "        major = ord(arr[6:7])\n",
    "        assert major == 1, \"this only reads version 1\"\n",
    "        minor = ord(arr[7:8])\n",
    "        header_len = int.from_bytes(arr[8:10], \"little\")\n",
    "        header_str = f.read(header_len)\n",
    "        header = ast.literal_eval(header_str.decode(\"ascii\"))\n",
    "        \n",
    "        assert magic == b\"\\x93NUMPY\"\n",
    "        assert (len(arr) + header_len) % 64 == 0\n",
    "        assert isinstance(header, dict)\n",
    "        dtype = np.dtype(header[\"descr\"])  # dtype will be str\n",
    "        fortran_order = header[\"fortran_order\"]\n",
    "        shape = header[\"shape\"]\n",
    "        assert isinstance(fortran_order, bool)\n",
    "        assert isinstance(shape, tuple)\n",
    "        assert len(shape) == 1\n",
    "        \n",
    "        # instantiate the array\n",
    "        array = np.ndarray(shape, dtype=dtype)\n",
    "        # read the data\n",
    "        data = f.read()\n",
    "        # populate the array\n",
    "        array[:] = np.frombuffer(data, dtype=dtype)\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1,   2,   3,   4,   5, 100, 200, 300, 400, 500, 600, 700, 800])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_array = read_npy_v1(filename)\n",
    "new_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert np.all(original_array == new_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions?\n",
    "\n",
    "I really appreciate the beautiful simplicity of the fileformat. \n",
    "\n",
    "I think the next step for me is to read/write `.npy` from `nim`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "pathlib.Path(filename).unlink()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pages310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
