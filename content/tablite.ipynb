{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning data in the field of logistics, parsing csv files, excel files\n",
    "and scrubbing `utf-8`, `utf-16` and `windows1250` data for a decade, I thought\n",
    "it was overdue to synthesize my experiences into a compact clean python package.\n",
    "\n",
    "However before I start, I want to highlight ***why***. \n",
    "\n",
    "First of all we're all tired of reinventing the wheel when we need to process \n",
    "a bit of data. So we pick some package and try to get it to work:\n",
    "\n",
    "**Pandas** features pythonic slicing and an easy to navigate api, but when using \n",
    "Pandas, there's always a huge memory overhead. I never took the time\n",
    "to investigate, but x10 - x20 times the raw file seems common. In my line of \n",
    "work that was often enough not to be able to use pandas at all.\n",
    "\n",
    "**Numpy** is of course close to the metal, and thereby \"fast\" for data processing.\n",
    "But fast is really not the problem in dirty data. It's the `None`'s or `Nan`'s\n",
    "that numpy doesn't cope well with, so it would make me jump through various \n",
    "hoops to get the data into a state where numpy would be usable. Last but not\n",
    "least, Numpy has become a language of it's own. I'm sorry to say it but it just \n",
    "doesn't seem pythonic anymore.\n",
    "\n",
    "**Arrows** looks like all the great things, but it just isn't ready.\n",
    "\n",
    "**SQLite** is great but just too slow, particularly on disk. Even with WAL off,\n",
    "inserting 200,000 rows per second into a new table no fun, and after that, doing\n",
    "repeated incremental queries, become painful. Creating temporary tables that help\n",
    "to avoid rerunning of queries, always become necessary. A second element is that\n",
    "SQLite doesn't `vacuum` itself. A user who does an outer join on 40,000 x 40,000\n",
    "rows of data, generates 1,600,000,000 temporary records - or 8,000 seconds of inserts - \n",
    "which just isn't workable.\n",
    "\n",
    "**Protobuffer** is nice for making the data portable, but the overhead of making \n",
    "dirty data fit the form, is just as laborious as implementing all the analytics \n",
    "that need to happen afterwards.\n",
    "\n",
    "\n",
    "So where do we end up? We write some custom built class for the problem at hand and\n",
    "discover that we've just spent 3 hours doing something that should have taken\n",
    "20 minutes.\n",
    "\n",
    "### No more! \n",
    "\n",
    "I listened to the old adage that good artists copy, great artist steal, and took\n",
    "the best of all.\n",
    "\n",
    "### ...Enter: [tablite](https://pypi.org/project/tablite)\n",
    "\n",
    "A python library for tables that does everything you need.\n",
    "\n",
    "- it handles all real world datatypes: str,float,bool,int,date,datetime,time.\n",
    "- it behaves like a dict/list, so it can be learned in 10 minutes.\n",
    "- it loads data and determines the data types in one line of code for `csv`, `tsv`, `txt`, `xlsx`, `xls`, `xlsm`, `ods`.\n",
    "- it detects all date,time and datetime formats covered in dateutil and the turing institutes publicly available tests.\n",
    "- it is portable as JSON in a single function call. \n",
    "- It has all the main stream analytics packaged: SQL join, pandas Groupby, All, Any, Filter\n",
    "- It supports incremental analytics using `+=` \n",
    "- It has datatype validation\n",
    "- and finally it makes YOU blazingly fast. \n",
    "\n",
    "Pun intended in the last line. Most packages advertise that the code they've \n",
    "made is **_blazingly fast_**. I think it's bullocks -  A package is as\n",
    "fast as the underlying algorithms and programming language allows it to be. \n",
    "What matters to me is I can solve a data clean up task in about 3 minutes. \n",
    "That's fast to me. Not that I can repeatedly run through dirty\n",
    "data at 4 million rows per second, but then spend all day on making the data fit \n",
    "into the framework.\n",
    "   \n",
    "For more details go to: [tablite](https://pypi.org/project/tablite) \n",
    "[![Build Status](https://travis-ci.com/root-11/tablite.svg?branch=master)](https://travis-ci.org/root-11/tablite) \n",
    "[![Code coverage](https://codecov.io/gh/root-11/tablite/branch/master/graph/badge.svg)](https://codecov.io/gh/root-11/tablite)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
